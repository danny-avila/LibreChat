# E2B Data Analyst Agent 高级测试用例

## 测试环境准备
- 测试数据集：`titanic.csv`（Kaggle Titanic数据集）
- 测试用户：已登录的LibreChat用户
- 测试端点：E2B Assistants
- Azure OpenAI 配置：
  - Endpoint: `https://hkubs-airi.cognitiveservices.azure.com/`
  - Model: `gpt-4.1`
  - API Version: `2025-01-01-preview`

---

## 测试场景 7: Web 爬虫与数据采集

### 第1轮 - 基础网页抓取
**Prompt**:
```
使用 requests 和 BeautifulSoup 抓取 https://httpbin.org/html 的内容，提取所有段落文本并统计词频（Top 10）
```

**预期结果**:
- ✅ 成功发起 HTTP 请求
- ✅ 正确解析 HTML
- ✅ 提取文本内容
- ✅ 统计词频并展示 Top 10
- ✅ 处理可能的网络错误

**已知限制**:
- ⚠️ E2B 沙箱可能对某些网站有访问限制
- ⚠️ 需要设置合理的 User-Agent
- ⚠️ 可能需要处理超时（建议 timeout=10）

---

### 第2轮 - API 数据抓取与分析
**Prompt**:
```
使用 yfinance 库获取苹果公司（AAPL）最近3个月的股票数据，计算：
1. 每日收益率
2. 移动平均线（5日、20日）
3. 波动率
4. 生成价格走势图和收益率分布图
```

**预期结果**:
- ✅ 成功调用 yfinance API
- ✅ 获取历史股票数据
- ✅ 正确计算技术指标
- ✅ 生成专业的金融图表
- ✅ 处理数据缺失情况

**测试要点**:
- 是否正确处理时间序列数据
- 移动平均线计算准确性
- 图表可读性和专业性

---

### 第3轮 - 复杂爬虫场景
**Prompt**:
```
从 https://jsonplaceholder.typicode.com/posts 获取前20条帖子数据，对每条帖子：
1. 提取标题和正文
2. 分析正文的情感倾向（简单的正面/负面词统计）
3. 统计标题长度分布
4. 生成可视化报告（饼图显示情感分布，直方图显示标题长度）
```

**预期结果**:
- ✅ 成功获取 JSON API 数据
- ✅ 正确解析和处理数据
- ✅ 实现简单的情感分析逻辑
- ✅ 生成多个可视化图表
- ✅ 提供综合分析报告

---

## 测试场景 8: 复杂机器学习任务

### 第1轮 - 完整的机器学习流程
**操作**: 上传 `titanic.csv`
**Prompt**:
```
执行完整的机器学习预测任务：
1. 数据预处理（处理缺失值、类别编码、特征缩放）
2. 特征工程（创建新特征：FamilySize, IsAlone, Title等）
3. 训练多个模型（逻辑回归、随机森林、XGBoost）
4. 交叉验证评估（5折）
5. 超参数调优（GridSearchCV）
6. 生成特征重要性图、混淆矩阵、ROC曲线
7. 输出最佳模型的详细性能报告
```

**预期结果**:
- ✅ 完成完整的数据预处理流程
- ✅ 成功训练多个模型
- ✅ 正确执行交叉验证
- ✅ 超参数调优合理
- ✅ 生成专业的评估图表
- ✅ 提供详细的性能对比

**性能要求**:
- ⚠️ 任务可能需要 5-10 分钟完成
- ✅ 系统应在 20 次迭代内完成
- ✅ 在接近迭代限制时应提供中间结果

---

### 第2轮 - 集成学习与模型融合
**Prompt**:
```
基于上一步训练的模型，实现 Stacking 集成：
1. 使用逻辑回归、随机森林、XGBoost 作为基模型
2. 使用另一个逻辑回归作为元模型
3. 对比 Stacking 模型与单个模型的性能
4. 生成学习曲线，分析模型的偏差-方差权衡
```

**预期结果**:
- ✅ 正确实现 Stacking 集成
- ✅ 性能提升可量化
- ✅ 生成学习曲线图
- ✅ 提供深入的模型分析

---

### 第3轮 - 深度学习实验（PyTorch）
**操作**: 上传 `titanic.csv`
**Prompt**:
```
使用 PyTorch 构建一个简单的神经网络预测生存率：
1. 数据预处理和归一化
2. 构建 3 层全连接网络（64-32-16-1）
3. 使用 Adam 优化器，Binary Cross Entropy 损失
4. 训练 50 个 epoch，记录训练和验证损失
5. 绘制损失曲线
6. 输出最终准确率和混淆矩阵
```

**预期结果**:
- ✅ 成功构建 PyTorch 模型
- ✅ 正确实现训练循环
- ✅ 生成损失曲线图
- ✅ 模型收敛正常
- ✅ 提供性能评估

**测试要点**:
- PyTorch 是否可用（在允许的库列表中）
- 训练过程是否稳定
- 内存使用是否合理

---

## 测试场景 9: 大模型 API 调用

### 第1轮 - 文本分析任务
**操作**: 上传包含客户评论的 CSV 文件
**Prompt**:
```
使用 Azure OpenAI API (gpt-4.1) 分析客户评论的情感和主题：
1. 读取评论数据
2. 对每条评论调用 gpt-4.1 进行情感分析（积极/中性/消极）
3. 提取关键主题和问题点
4. 统计情感分布
5. 生成情感分布饼图和词云
6. 输出最具代表性的积极和消极评论示例

API 配置：
- Endpoint: os.environ.get('AZURE_OPENAI_ENDPOINT')
- API Key: os.environ.get('AZURE_OPENAI_API_KEY')
- Deployment: 'gpt-4.1'
- API Version: '2025-01-01-preview'
```

**预期结果**:
- ✅ 成功配置 Azure OpenAI 客户端
- ✅ 正确读取环境变量
- ✅ API 调用成功（处理速率限制）
- ✅ 情感分析准确
- ✅ 生成可视化结果
- ✅ 提供洞察性总结

**代码示例**:
```python
import os
from openai import AzureOpenAI

# 从环境变量读取配置
client = AzureOpenAI(
    azure_endpoint=os.environ.get('AZURE_OPENAI_ENDPOINT'),
    api_key=os.environ.get('AZURE_OPENAI_API_KEY'),
    api_version=os.environ.get('AZURE_OPENAI_API_VERSION', '2025-01-01-preview')
)

# 调用 API
response = client.chat.completions.create(
    model='gpt-4.1',  # 使用 deployment name
    messages=[
        {"role": "system", "content": "你是一个情感分析专家"},
        {"role": "user", "content": f"分析以下评论的情感：{review_text}"}
    ]
)
```

**错误处理**:
- ⚠️ 处理 API 速率限制（429）
- ⚠️ 处理超时和网络错误
- ⚠️ 验证环境变量是否存在

---

### 第2轮 - 批量内容生成
**Prompt**:
```
使用 gpt-4.1 为 Titanic 数据集的每个乘客等级生成营销文案：
1. 分析各等级乘客的特征（年龄、票价、生存率）
2. 对每个等级调用 gpt-4.1 生成 3 条营销文案
3. 每条文案约 100 字，突出该等级的特点
4. 将结果整理成表格展示
5. 分析文案的关键词频率

使用相同的 Azure OpenAI 配置
```

**预期结果**:
- ✅ 批量调用 API（处理 3 个等级）
- ✅ 生成高质量文案
- ✅ 文案与数据特征一致
- ✅ 正确格式化输出
- ✅ 提供关键词分析

---

### 第3轮 - 代码生成与执行
**Prompt**:
```
使用 gpt-4.1 作为编程助手，完成以下任务：
1. 要求 gpt-4.1 生成一个 Python 函数，用于计算时间序列数据的自相关函数
2. 执行生成的代码（在生成随机时间序列数据上测试）
3. 如果代码有错误，将错误信息反馈给 gpt-4.1，要求修正
4. 最多尝试 3 次，直到代码正确运行
5. 绘制自相关图
6. 总结整个过程

配置同上
```

**预期结果**:
- ✅ gpt-4.1 生成可执行代码
- ✅ 正确执行代码或处理错误
- ✅ 实现错误反馈循环
- ✅ 最终得到正确结果
- ✅ 展示迭代修正过程

**测试要点**:
- LLM 生成代码的质量
- 错误处理和重试机制
- 最终代码的正确性

---

### 第4轮 - 多轮对话与上下文管理
**Prompt**:
```
与 gpt-4.1 进行多轮对话分析 Titanic 数据：
1. 第一轮：询问数据集的主要发现（提供数据概览）
2. 第二轮：基于回答，询问如何提高预测准确率
3. 第三轮：要求提供具体的特征工程建议
4. 第四轮：基于建议实现特征工程并报告结果
5. 展示完整的对话历史和每轮的见解

每轮调用都维护对话历史
```

**预期结果**:
- ✅ 正确维护多轮对话上下文
- ✅ gpt-4.1 提供连贯的建议
- ✅ 实现建议并验证效果
- ✅ 展示对话流程
- ✅ 提供综合性总结

---

## 测试场景 10: 长时间运行任务

### 第1轮 - 大规模数据模拟
**Prompt**:
```
执行大规模蒙特卡洛模拟：
1. 模拟 10,000 次 Titanic 灾难场景
2. 每次模拟中随机调整关键参数（救生艇数量、逃生时间等）
3. 计算每种场景下的预期生存率
4. 找出影响生存率的最关键因素
5. 生成敏感性分析图表
6. 估计任务进度（每 1000 次输出进度）

预计运行时间：5-10 分钟
```

**预期结果**:
- ✅ 任务能够长时间运行
- ✅ 定期输出进度更新
- ✅ 最终完成所有模拟
- ✅ 生成有意义的分析结果
- ✅ 不超过迭代限制（20次）

**测试要点**:
- 长时间运行的稳定性
- 进度报告机制
- 内存和性能管理

---

### 第2轮 - 复杂优化问题
**Prompt**:
```
使用遗传算法优化 Titanic 救援策略：
1. 定义救援策略参数（救生艇分配、优先级规则等）
2. 实现遗传算法（种群大小 100，代数 50）
3. 适应度函数：最大化生存人数，同时考虑公平性
4. 每 10 代输出最佳策略和适应度
5. 绘制适应度进化曲线
6. 输出最优救援策略的详细说明

预计运行时间：8-15 分钟
```

**预期结果**:
- ✅ 遗传算法正确实现
- ✅ 任务稳定运行
- ✅ 定期输出中间结果
- ✅ 最终找到优化解
- ✅ 提供清晰的策略说明

---

### 第3轮 - 深度学习训练（长时间）
**Prompt**:
```
训练一个更复杂的神经网络：
1. 构建 5 层深度网络，加入 Dropout 和 Batch Normalization
2. 训练 200 个 epoch
3. 每 20 个 epoch 输出训练进度和当前性能
4. 实现 Early Stopping（patience=30）
5. 保存最佳模型权重
6. 绘制详细的学习曲线（训练/验证 loss 和 accuracy）
7. 进行模型分析（过拟合/欠拟合诊断）

预计运行时间：10-20 分钟
```

**预期结果**:
- ✅ 训练过程稳定
- ✅ 定期输出进度
- ✅ Early Stopping 正确触发
- ✅ 生成完整的训练曲线
- ✅ 提供模型诊断

---

## 测试场景 11: 综合集成场景

### 完整工作流：数据获取 → AI分析 → 预测 → 报告
**Prompt**:
```
执行端到端数据科学项目：

第一阶段：数据获取
1. 使用 yfinance 获取 AAPL 和 GOOGL 过去 6 个月的股票数据
2. 从 https://jsonplaceholder.typicode.com/users 获取用户数据作为客户信息

第二阶段：数据分析
3. 计算股票的技术指标（RSI、MACD、布林带）
4. 分析股票的相关性和协整性

第三阶段：AI 增强分析
5. 调用 gpt-4.1 分析股票走势并提供投资建议
6. 对每只股票生成 200 字的分析报告

第四阶段：预测建模
7. 使用 LSTM 或简单的时间序列模型预测未来 5 天的价格
8. 计算预测的置信区间

第五阶段：综合报告
9. 生成包含所有图表的综合报告
10. 使用 gpt-4.1 生成执行摘要（500 字）

预计运行时间：15-25 分钟
```

**预期结果**:
- ✅ 完成所有五个阶段
- ✅ 每个阶段输出清晰的结果
- ✅ API 调用成功（yfinance + Azure OpenAI）
- ✅ 预测模型合理
- ✅ 生成专业的综合报告
- ✅ 提供可操作的洞察

**测试要点**:
- 多种技术的集成能力
- 长时间运行的稳定性
- 结果的专业性和可读性
- 是否在 20 次迭代内完成

---

## 错误场景测试

### API 错误处理
**Prompt**:
```
测试 Azure OpenAI API 的错误处理：
1. 尝试使用错误的 API key（修改环境变量）
2. 尝试调用不存在的模型
3. 发送超长的 prompt（超过 token 限制）
4. 快速连续调用（触发速率限制）

对每种错误场景，展示如何优雅地处理
```

**预期结果**:
- ✅ 正确识别各种错误类型
- ✅ 提供清晰的错误信息
- ✅ 实现重试机制（针对速率限制）
- ✅ 不会崩溃或挂起

---

### 网络错误模拟
**Prompt**:
```
测试爬虫的错误处理能力：
1. 访问不存在的 URL
2. 访问需要认证的资源
3. 访问响应缓慢的服务（设置 timeout）
4. 处理乱码或无效的 HTML

展示每种情况的处理方式
```

**预期结果**:
- ✅ 优雅处理各种网络错误
- ✅ 提供有用的错误信息
- ✅ 实现超时保护
- ✅ 任务不会因错误而中断

---

## 性能基准测试

### 计算密集型任务
**Prompt**:
```
执行性能基准测试：
1. 矩阵运算：1000x1000 矩阵乘法（重复 100 次）
2. 数值计算：计算 π 到 100,000 位小数
3. 统计模拟：运行 10,000 次 bootstrap 采样
4. 排序算法：对 1,000,000 个随机数排序

记录每个任务的执行时间并比较
```

**预期结果**:
- ✅ 所有任务成功完成
- ✅ 执行时间合理
- ✅ 不超过内存限制
- ✅ 提供性能报告

---

## 检查清单

### 高级功能
- [ ] 网络请求（爬虫）
- [ ] 外部 API 调用（yfinance, Azure OpenAI）
- [ ] 复杂机器学习任务
- [ ] 深度学习（PyTorch）
- [ ] 长时间运行任务（>5分钟）
- [ ] 环境变量读取

### 错误处理
- [ ] API 错误处理
- [ ] 网络超时
- [ ] 速率限制处理
- [ ] 内存溢出保护

### 性能
- [ ] 长时间任务不超时
- [ ] 进度报告清晰
- [ ] 不超过迭代限制
- [ ] 内存使用合理

### AI 集成
- [ ] Azure OpenAI 调用成功
- [ ] gpt-4.1 模型正常工作
- [ ] 多轮对话上下文管理
- [ ] AI 生成内容质量

---

## 测试报告模板

```markdown
## 测试日期: YYYY-MM-DD
## 测试人员: [姓名]
## 版本: [版本号]

### 场景7: Web 爬虫
- 第1轮: ✅/❌ [备注]
- 第2轮: ✅/❌ [备注]
- 第3轮: ✅/❌ [备注]

### 场景8: 复杂机器学习
- 第1轮: ✅/❌ [运行时间: _分钟]
- 第2轮: ✅/❌ [运行时间: _分钟]
- 第3轮: ✅/❌ [运行时间: _分钟]

### 场景9: 大模型 API 调用
- 第1轮: ✅/❌ [API 调用次数: _]
- 第2轮: ✅/❌ [API 调用次数: _]
- 第3轮: ✅/❌ [API 调用次数: _]
- 第4轮: ✅/❌ [API 调用次数: _]

### 场景10: 长时间运行
- 第1轮: ✅/❌ [实际运行时间: _分钟]
- 第2轮: ✅/❌ [实际运行时间: _分钟]
- 第3轮: ✅/❌ [实际运行时间: _分钟]

### 场景11: 综合集成
- 完整流程: ✅/❌ [总运行时间: _分钟, 迭代次数: _]

### 错误场景测试
- API 错误处理: ✅/❌ [备注]
- 网络错误处理: ✅/❌ [备注]

### 性能基准
- 计算密集型: ✅/❌ [各任务时间]

### 发现的问题
1. [问题描述]
   - 重现步骤: 
   - 预期结果:
   - 实际结果:
   - 严重程度: 高/中/低

### Azure OpenAI 集成评估
- 环境变量读取: ✅/❌
- API 连接稳定性: __/10
- gpt-4.1 响应质量: __/10
- 错误处理完善性: __/10

### 总体评分
- 高级功能完整性: __/10
- 长时间运行稳定性: __/10
- 错误处理完善性: __/10
- AI 集成质量: __/10
- 性能表现: __/10
```
