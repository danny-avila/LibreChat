# Woodland Pipeline Testing

Comprehensive end-to-end testing framework for the Woodland Knowledge Pipeline.

## ğŸ¯ Test Suites

### 1. Unit Tests (`tests/unit/`)
Tests individual parsers and functions in isolation.

### 2. Integration Tests (`tests/integration/`)
Tests real Woodland agent responses with knowledge base queries.

### 3. End-to-End Tests (`tests/e2e/`)
Tests complete pipeline workflow: Build â†’ Validate â†’ Index â†’ Query

## ğŸš€ Running Tests

### Quick Start
```bash
# Run all tests
npm test

# Run specific suite
npm run test:unit
npm run test:integration
npm run test:e2e

# Generate HTML report
npm run test:report
```

### Integration Test (Agent Queries)
```bash
# Set environment variables
export LIBRECHAT_URL=http://localhost:3080
export WOODLAND_TEST_API_KEY=your_api_key

# Run agent integration tests
npm run test:integration
```

**Output**: `tests/reports/integration-test-report.json`

### End-to-End Pipeline Test
```bash
# Minimal (build + validate only)
npm run test:e2e

# Full pipeline (with indexing + agent tests)
export RAG_API_URL=http://localhost:8001
export AZURE_AI_SEARCH_ENDPOINT=https://your-search.search.windows.net
export LIBRECHAT_URL=http://localhost:3080
npm run test:e2e
```

**Output**:
- HTML Report: `tests/reports/pipeline-e2e-report.html`
- JSON Report: `tests/reports/pipeline-e2e-report.json`

## ğŸ“Š Test Reports

### HTML Report Features
- âœ… Overall pass/fail status
- ğŸ“ˆ Stage-by-stage breakdown
- ğŸ“Š Metrics and statistics
- ğŸ¨ Visual progress indicators
- â±ï¸ Performance timing
- ğŸ“ Detailed error messages

### Integration Test Metrics
- **Keyword Match**: Percentage of expected keywords found in responses
- **Quality Score**: Response completeness, length, readability
- **Response Time**: Agent query latency
- **Pass Rate**: Overall test success rate
- **Category Breakdown**: Results by question category

## ğŸ§ª Test Fixtures

### Test Questions (`tests/fixtures/test-questions.json`)
Curated test cases covering:
- Product specifications
- Installation process
- Financial/tax information
- Technical specifications
- Maintenance requirements
- Legal/permitting questions

Each test case includes:
- Question text
- Expected keywords (for validation)
- Category classification

### Adding Test Cases
```json
{
  "id": "test_qa_011",
  "question": "Your test question here?",
  "expected_keywords": ["keyword1", "keyword2", "keyword3"],
  "category": "product_specs"
}
```

## ğŸ“‹ Test Workflow

### Standard E2E Test Flow
```
1. Build Datasets
   â”œâ”€ Parse QA sources (CSV + .docx)
   â”œâ”€ Parse training data
   â”œâ”€ Parse sales conversations
   â””â”€ Generate unified dataset

2. Validate Datasets
   â”œâ”€ Check required fields
   â”œâ”€ Validate JSON parsing
   â”œâ”€ Detect duplicates
   â””â”€ Apply quality gates

3. Index to RAG (Optional)
   â””â”€ Upload to LibreChat RAG API

4. Index to Azure (Optional)
   â””â”€ Upload to Azure AI Search

5. Agent Integration Tests
   â”œâ”€ Query Woodland agents
   â”œâ”€ Validate responses
   â”œâ”€ Measure quality
   â””â”€ Generate report
```

## ğŸ¯ Success Criteria

### Build Stage
- âœ… All source files parsed successfully
- âœ… Expected item counts met
- âœ… Output files generated

### Validation Stage
- âœ… No critical errors
- âœ… Warnings below threshold
- âœ… All required fields present

### Agent Tests
- âœ… 80%+ pass rate
- âœ… 50%+ keyword match on average
- âœ… 60%+ quality score on average
- âœ… Response time < 5000ms

## ğŸ› ï¸ Configuration

### Environment Variables

```bash
# LibreChat Integration
LIBRECHAT_URL=http://localhost:3080
WOODLAND_TEST_API_KEY=your_api_key
TEST_USER_ID=mongodb_user_id

# RAG Indexing (Optional)
RAG_API_URL=http://localhost:8001

# Azure AI Search (Optional)
AZURE_AI_SEARCH_ENDPOINT=https://your-search.search.windows.net
AZURE_AI_SEARCH_ADMIN_KEY=your_admin_key
AZURE_AI_SEARCH_INDEX_NAME=woodland-qa-hybrid

# Azure OpenAI (for embeddings)
AZURE_OPENAI_API_KEY=your_key
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com
AZURE_OPENAI_DEPLOYMENT_NAME=text-embedding-ada-002
```

### Optional Stages
If environment variables are not set, those stages are skipped:
- RAG indexing â†’ Skipped if no `RAG_API_URL`
- Azure indexing â†’ Skipped if no `AZURE_AI_SEARCH_ENDPOINT`
- Agent tests â†’ Skipped if no `LIBRECHAT_URL`

## ğŸ“ˆ Example Output

### Console Output
```
ğŸš€ Starting Woodland Pipeline End-to-End Tests

============================================================
STAGE 1: BUILD DATASETS
============================================================
ğŸ“¦ Building datasets from all sources...
âœ… Building datasets from all sources completed

============================================================
STAGE 2: VALIDATE DATASETS
============================================================
ğŸ“¦ Validating dataset quality...
âœ… Validating dataset quality completed

============================================================
STAGE 5: AGENT INTEGRATION TESTS
============================================================
ğŸ” Testing: test_qa_001
   Question: "What is the warranty period for Woodland solar panels?"
   âœ… PASSED
   Keyword match: 85.0%
   Quality score: 78.5%
   Response time: 1234ms

============================================================
ğŸ“Š E2E TEST COMPLETE
============================================================
Overall Status: âœ… PASS
Total Time: 45.23s

ğŸ“„ HTML Report: tests/reports/pipeline-e2e-report.html
ğŸ“„ JSON Report: tests/reports/pipeline-e2e-report.json
```

### HTML Report Preview
Open `tests/reports/pipeline-e2e-report.html` in browser to see:
- Visual dashboard with metrics
- Stage-by-stage results
- Progress indicators
- Detailed breakdowns

## ğŸ” Troubleshooting

### Agent Tests Failing
- Verify `LIBRECHAT_URL` is accessible
- Check API key validity
- Ensure knowledge base is indexed
- Review test questions relevance

### Build Stage Failing
- Check data file formats (CSV, JSON, .docx)
- Verify file permissions
- Review parser error messages

### Validation Warnings
- Review `build/validation_report.json`
- Check for duplicate IDs
- Validate JSON structure in metadata

### Indexing Failures
- Verify RAG API/Azure Search endpoints
- Check authentication credentials
- Review network connectivity
- Confirm index schema compatibility

## ğŸš€ CI/CD Integration

### GitHub Actions Example
```yaml
name: Pipeline Tests
on: [push, pull_request]
jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-node@v3
        with:
          node-version: '18'
      - run: cd woodland-pipeline && npm install
      - run: cd woodland-pipeline && npm run test:e2e
      - uses: actions/upload-artifact@v3
        with:
          name: test-reports
          path: woodland-pipeline/tests/reports/
```

## ğŸ“ Best Practices

1. **Run tests before deployment**: `npm run test:all`
2. **Review HTML reports**: Check detailed metrics
3. **Monitor pass rates**: Maintain >80% agent test success
4. **Update test fixtures**: Add new questions as knowledge grows
5. **Version test reports**: Keep historical reports for comparison

## ğŸ¤ Contributing

When adding features:
1. Add corresponding test cases
2. Update test fixtures if needed
3. Ensure all tests pass
4. Document new test scenarios

---

**Need help?** See [../docs/QUICKSTART.md](../docs/QUICKSTART.md) for pipeline documentation.
