##########################
# Server configuration: 
##########################

# The server will listen to localhost:3080 by default. You can change the target IP as you want. 
# If you want to make this server available externally, for example to share the server with others 
# or expose this from a Docker container, set host to 0.0.0.0 or your external IP interface. 
# Tips: Setting host to 0.0.0.0 means listening on all interfaces. It's not a real IP.  
# Use localhost:port rather than 0.0.0.0:port to access the server. 
# Set Node env to development if running in dev mode.
HOST=localhost
PORT=3080
NODE_ENV=production 

# Change this to proxy any API request. 
# It's useful if your machine has difficulty calling the original API server. 
# PROXY=

# Change this to your MongoDB URI if different. I recommend appending chatgpt-clone. 
MONGO_URI=mongodb://127.0.0.1:27017/chatgpt-clone

##########################
# OpenAI Endpoint: 
##########################

# Access key from OpenAI platform. 
# Leave it blank to disable this feature.
# Set to "user_provided" to allow the user to provide their API key from the UI.
OPENAI_KEY=

# Identify the available models, separated by commas *without spaces*. 
# The first will be default. 
# Leave it blank to use internal settings. 
OPENAI_MODELS=gpt-3.5-turbo,gpt-3.5-turbo-0301,text-davinci-003,gpt-4,gpt-4-0314

# Reverse proxy settings for OpenAI: 
# https://github.com/waylaidwanderer/node-chatgpt-api#using-a-reverse-proxy 
# OPENAI_REVERSE_PROXY=

##########################
# AZURE Endpoint:   
##########################

# To use Azure with this project, set the following variables. These will be used to build the API URL.
# Chat completion: 
#     `https://{AZURE_OPENAI_API_INSTANCE_NAME}.openai.azure.com/openai/deployments/{AZURE_OPENAI_API_DEPLOYMENT_NAME}/chat/completions?api-version={AZURE_OPENAI_API_VERSION}`;
# You should also consider changing the `OPENAI_MODELS` variable above to the models available in your instance/deployment.
# Note: I've noticed that the Azure API is much faster than the OpenAI API, so the streaming looks almost instantaneous.

# AZURE_OPENAI_API_KEY=
# AZURE_OPENAI_API_INSTANCE_NAME=
# AZURE_OPENAI_API_DEPLOYMENT_NAME=
# AZURE_OPENAI_API_VERSION=
# AZURE_OPENAI_API_COMPLETIONS_DEPLOYMENT_NAME= # Optional, but may be used in future updates
# AZURE_OPENAI_API_EMBEDDINGS_DEPLOYMENT_NAME= # Optional, but may be used in future updates

##########################
# BingAI Endpoint:   
##########################

# Also used for Sydney and jailbreak

# BingAI Tokens: the "_U" cookies value from bing.com 
# Set to "user_provided" to allow the user to provide its token from the UI.
# Leave it blank to disable this endpoint. 
BINGAI_TOKEN="user_provided"

# BingAI Host: 
# Necessary for some people in different countries, e.g. China (https://cn.bing.com) 
# Leave it blank to use default server. 
# BINGAI_HOST=https://cn.bing.com 

##########################
# ChatGPT Endpoint: 
##########################

# ChatGPT Browser Client (free but use at your own risk) 
# Access token from https://chat.openai.com/api/auth/session 
# Exposes your access token to `CHATGPT_REVERSE_PROXY`
# Set to "user_provided" to allow the user to provide its token from the UI.
# Leave it blank to disable this endpoint 
CHATGPT_TOKEN="user_provided"

# Identify the available models, separated by commas. The first will be default. 
# Leave it blank to use internal settings. 
CHATGPT_MODELS=text-davinci-002-render-sha,gpt-4
# NOTE: you can add gpt-4-plugins, gpt-4-code-interpreter, and gpt-4-browsing to the list above and use the models for these features;
# however, the view/display portion of these features are not supported, but you can use the underlying models, which have higher token context
# Also: text-davinci-002-render-paid is deprecated as of May 2023

# Reverse proxy settings for ChatGPT 
# https://github.com/waylaidwanderer/node-chatgpt-api#using-a-reverse-proxy 
# By default, the server will use the node-chatgpt-api recommended proxy (a third party server). 
# CHATGPT_REVERSE_PROXY= 

##########################
# PaLM (Google) Endpoint: 
##########################

# PaLM 2 Client (via Google Cloud Vertex AI API)
# Steps:
    # Enable the Vertex AI API on Google Cloud:
        # https://console.cloud.google.com/vertex-ai
    # Create a Service Account:
        # https://console.cloud.google.com/projectselector/iam-admin/serviceaccounts/create?walkthrough_id=iam--create-service-account#step_index=1
    # Make sure to click 'Create and Continue' to give at least the 'Vertex AI User' role.
    # Create a JSON key, rename as 'auth.json' and save it in /api/data/.
# Alternatively
    # Uncomment below PALM_KEY and set as "user_provided" to allow the user to provide a Service Account key JSON from the UI.
    # They will follow the steps above except for renaming the file.
# Leave blank or omit to disable this endpoint 

# PALM_KEY="user_provided"

# In case you need a reverse proxy for this endpoint:
# GOOGLE_REVERSE_PROXY= 

##########################
# Proxy: To be Used by all endpoints
##########################
PROXY=

##########################
# Search: 
##########################

# ENABLING SEARCH MESSAGES/CONVOS 
# Requires the installation of the free self-hosted Meilisearch or a paid Remote Plan (Remote not tested) 
# The easiest setup for this is through docker-compose, which takes care of it for you. 
SEARCH=false

# REQUIRED FOR SEARCH: MeiliSearch Host, mainly for the API server to connect to the search server. 
# Replace '0.0.0.0' with 'meilisearch' if serving MeiliSearch with docker-compose. 
MEILI_HOST=http://0.0.0.0:7700

# REQUIRED FOR SEARCH: MeiliSearch HTTP Address, mainly for docker-compose to expose the search server. 
# Replace '0.0.0.0' with 'meilisearch' if serving MeiliSearch with docker-compose. 
MEILI_HTTP_ADDR=0.0.0.0:7700

# REQUIRED FOR SEARCH: In production env., a secure key is needed. You can generate your own. 
# This master key must be at least 16 bytes, composed of valid UTF-8 characters. 
# MeiliSearch will throw an error and refuse to launch if no master key is provided, 
# or if it is under 16 bytes. MeiliSearch will suggest a secure autogenerated master key.
# Using docker, it seems recognized as production so use a secure key.
# This is a ready made secure key for docker-compose, you can replace it with your own.
MEILI_MASTER_KEY=DrhYf7zENyR6AlUCKmnz0eYASOQdl6zxH7s7MKFSfFCt

##########################
# User System:
##########################

# JWT Secrets
JWT_SECRET=secret
JWT_REFRESH_SECRET=secret

# Google:
# Add your Google Client ID and Secret here, you must register an app with Google Cloud to get these values
# https://cloud.google.com/
GOOGLE_CLIENT_ID=
GOOGLE_CLIENT_SECRET=
GOOGLE_CALLBACK_URL=/oauth/google/callback

# Set the expiration delay for the secure cookie with the JWT token
# Delay is in millisecond e.g. 7 days is 1000*60*60*24*7
SESSION_EXPIRY=1000 * 60 * 60 * 24 * 7

# Application Domains
# Note: server = backend, client = pubilc url you visit
DOMAIN_CLIENT=http://localhost:3090
DOMAIN_SERVER=http://localhost:3080

###########################
# Frontend Configuration (Vite):
###########################

# Custom app name, this text will be displayed in the landing page and the footer.
VITE_APP_TITLE="ChatGPT Clone"

###########################
# Server URL configuration: 
###########################

# The social login domain uses this to redirect to localhost:3080 when you run the app in dev mode with Vite.
# Use your domain name as the Prod URL when you deploy the app to a live domain.
# Please note that:  
# Social login features will not work if you run the build version on port 3080 locally after modifying the Prod URL 
VITE_SERVER_URL_DEV=http://localhost:3080
VITE_SERVER_URL_PROD=http://localhost:3080

# Enable Social Login
# This enables/disables the Login with Google button on the login page.
# Set to true if you have registered the app with google cloud services 
# and have set the GOOGLE_CLIENT_ID and GOOGLE_CLIENT_SECRET in the /api/.env file
VITE_SHOW_GOOGLE_LOGIN_OPTION=false