version: 1.2.4

cache: true

interface:
  privacyPolicy:
    externalUrl: 'https://librechat.ai/privacy-policy'
    openNewTab: true
  termsOfService:
    externalUrl: 'https://librechat.ai/tos'
    openNewTab: true

registration:
  socialLogins:
    - "discord"
    - "facebook"
    - "github"
    - "google"
    - "openid"

endpoints:
  custom:
  - name: "LiteLLM"
    apiKey: "${LITELLM_API_KEY}"
    baseURL: "${LITELLM_BASE_URL}"
    # if using LiteLLM example in docker-compose.override.yml.example, use "http://litellm:8000/v1"
    models:
      default: ["gpt-3.5-turbo"]
      fetch: true
    titleConvo: true
    titleModel: "gpt-3.5-turbo"
    summarize: false
    summaryModel: "gpt-3.5-turbo"
    forcePrompt: false
    modelDisplayLabel: "LiteLLM"

  - name: "LiteLLM-Embedding"
    apiKey: "${LITELLM_EMBEDDING_API_KEY:-sk-from-config-file}"
    baseURL: "${LITELLM_EMBEDDING_BASE_URL:-https://litellm.amendllc.com/v1}"
    models:
      default:
        - "text-embedding-ada-002"
        - "text-embedding-3-small"
        - "text-embedding-3-large"
      fetch: true
    titleConvo: true
    titleModel: "text-embedding-3-small"
    summarize: false
    summaryModel: "text-embedding-ada-002"
    forcePrompt: false
    modelDisplayLabel: "LiteLLM Embeddings"
    # # APIpie
    # # https://apipie.ai/dashboard/
    # # Script to fetch models: https://github.com/LibreChat-AI/librechat-config-yaml/blob/main/scripts/apipie.py
    # - name: "APIpie"
    #   apiKey: "user_provided"
    #   baseURL: "https://apipie.ai/v1/"
    #   models:
    #     default:
    #       - DeepSeek-Prover-V2-671B
    #       - DeepSeek-R1
    #       - DeepSeek-R1-Distill-Llama-70B
    #       - DeepSeek-R1-Distill-Llama-70B-free
    #       - DeepSeek-R1-Distill-Qwen-1.5B
    #       - DeepSeek-R1-Distill-Qwen-14B
    #       - DeepSeek-R1-Distill-Qwen-32B
    #       - DeepSeek-R1-Turbo
    #       - DeepSeek-V3
    #       - DeepSeek-V3-0324
    #       - DeepSeek-V3-p-dp
    #       - Hermes-3-Llama-3.1-405B
    #       - L3-70B-Euryale-v2.1
    #       - L3-8B-Lunaris-v1
    #       - L3-8B-Lunaris-v1-Turbo
    #       - L3.1-70B-Euryale-v2.2
    #       - L3.3-70B-Euryale-v2.3
    #       - LLaMA2-13B-Tiefighter
    #       - Llama-2-13b-chat-hf
    #       - Llama-2-70b-chat-hf
    #       - Llama-2-70b-hf
    #       - Llama-3-70b-chat-hf
    #       - Llama-3-8b-chat-hf
    #       - Llama-3.1-Nemotron-70B-Instruct
    #       - Llama-3.1-Nemotron-70B-Instruct-HF
    #       - Llama-3.2-11B-Vision-Instruct
    #       - Llama-3.2-11B-Vision-Instruct-Turbo
    #       - Llama-3.2-1B-Instruct
    #       - Llama-3.2-3B-Instruct
    #       - Llama-3.2-3B-Instruct-Turbo
    #       - Llama-3.2-90B-Vision-Instruct
    #       - Llama-3.2-90B-Vision-Instruct-Turbo
    #       - Llama-3.3-70B-Instruct
    #       - Llama-3.3-70B-Instruct-Turbo
    #       - Llama-3.3-70B-Instruct-Turbo-Free
    #       - Llama-4-Maverick-17B-128E-Instruct-FP8
    #       - Llama-4-Maverick-17B-128E-Instruct-Turbo
    #       - Llama-4-Scout-17B-16E-Instruct
    #       - Llama-Guard-3-8B
    #       - Llama-Guard-4-12B
    #       - Llama-Vision-Free
    #       - Meta-Llama-3-70B-Instruct
    #       - Meta-Llama-3-70B-Instruct-Turbo
    #       - Meta-Llama-3-8B-Instruct
    #       - Meta-Llama-3-8B-Instruct-Lite
    #       - Meta-Llama-3.1-405B-Instruct
    #       - Meta-Llama-3.1-405B-Instruct-Turbo
    #       - Meta-Llama-3.1-70B-Instruct
    #       - Meta-Llama-3.1-70B-Instruct-Turbo
    #       - Meta-Llama-3.1-8B-Instruct
    #       - Meta-Llama-3.1-8B-Instruct-Turbo
    #       - MiniCPM-Llama3-V-2_5
    #       - Mistral-7B-Instruct-v0.1
    #       - Mistral-7B-Instruct-v0.2
    #       - Mistral-7B-Instruct-v0.3
    #       - Mistral-Nemo-Instruct-2407
    #       - Mistral-Small-24B-Instruct-2501
    #       - Mixtral-8x22B-Instruct-v0.1
    #       - Mixtral-8x7B-Instruct-v0.1
    #       - MoA-1
    #       - MoA-1-Turbo
    #       - MythoMax-L2-13b
    #       - MythoMax-L2-13b-Lite
    #       - MythoMax-L2-13b-turbo
    #       - Nemotron-4-340B-Instruct
    #       - Nous-Hermes-2-Mixtral-8x7B-DPO
    #       - Phi-3-medium-4k-instruct
    #       - Phi-4-multimodal-instruct
    #       - Phind-CodeLlama-34B-v2
    #       - QVQ-72B-Preview
    #       - QwQ-32B
    #       - QwQ-32B-Preview
    #       - Qwen2-72B-Instruct
    #       - Qwen2-7B-Instruct
    #       - Qwen2-VL-72B-Instruct
    #       - Qwen2.5-72B-Instruct
    #       - Qwen2.5-72B-Instruct-Turbo
    #       - Qwen2.5-7B-Instruct
    #       - Qwen2.5-7B-Instruct-Turbo
    #       - Qwen2.5-Coder-32B-Instruct
    #       - Qwen2.5-Coder-7B
    #       - Qwen2.5-VL-72B-Instruct
    #       - Qwen3-14B
    #       - Qwen3-235B-A22B
    #       - Qwen3-235B-A22B-fp8
    #       - Qwen3-235B-A22B-fp8-tput
    #       - Qwen3-30B-A3B
    #       - Qwen3-32B
    #       - Reflection-Llama-3.1-70B
    #       - Refuel-Llm-V2
    #       - Refuel-Llm-V2-Small
    #       - Sky-T1-32B-Preview
    #       - Wan2.1-T2V-1.3B
    #       - WizardLM-2-7B
    #       - WizardLM-2-8x22B
    #       - aion-1.0
    #       - aion-1.0-mini
    #       - aion-rp-llama-3.1-8b
    #       - airoboros-70b
    #       - amazon.nova-lite-v1
    #       - amazon.nova-lite-v1:0
    #       - amazon.nova-micro-v1:0
    #       - amazon.nova-pro-v1:0
    #       - anubis-pro-105b-v1
    #       - arcee-blitz
    #       - babbage-002
    #       - caller-large
    #       - chatgpt-4o-latest
    #       - chatx
    #       - chatx-fast
    #       - chatx_cheap_128k
    #       - chatx_cheap_32k
    #       - chatx_cheap_4k
    #       - chatx_cheap_64k
    #       - chatx_cheap_8k
    #       - chatx_mids_4k
    #       - chatx_premium_128k
    #       - chatx_premium_32k
    #       - chatx_premium_4k
    #       - chatx_premium_8k
    #       - cheap
    #       - chronos-hermes-13b-v2
    #       - claude-2
    #       - claude-2.0
    #       - claude-2.1
    #       - claude-3-5-haiku
    #       - claude-3-5-haiku-20241022
    #       - claude-3-5-haiku-20241022-v1
    #       - claude-3-5-haiku-latest
    #       - claude-3-5-sonnet
    #       - claude-3-5-sonnet-20240620
    #       - claude-3-5-sonnet-20240620-v1
    #       - claude-3-5-sonnet-20241022
    #       - claude-3-5-sonnet-20241022-v2
    #       - claude-3-5-sonnet-latest
    #       - claude-3-7-sonnet-20250219
    #       - claude-3-7-sonnet-20250219-v1
    #       - claude-3-7-sonnet-latest
    #       - claude-3-haiku
    #       - claude-3-haiku-20240307
    #       - claude-3-haiku-20240307-v1
    #       - claude-3-opus
    #       - claude-3-opus-20240229
    #       - claude-3-opus-20240229-v1
    #       - claude-3-opus-latest
    #       - claude-3-sonnet
    #       - claude-3-sonnet-20240229
    #       - claude-3-sonnet-20240229-v1
    #       - claude-3.5-haiku
    #       - claude-3.5-haiku-20241022
    #       - claude-3.7-sonnet
    #       - claude-instant-v1
    #       - claude-v2
    #       - codegemma-7b-it
    #       - codellama-7b-instruct-solidity
    #       - coder-large
    #       - codestral-2405
    #       - codestral-2501
    #       - codestral-latest
    #       - codestral-mamba
    #       - codestral-mamba-latest
    #       - codex-mini
    #       - codex-mini-latest
    #       - command
    #       - command-a
    #       - command-light
    #       - command-light-nightly
    #       - command-light-text-v14
    #       - command-nightly
    #       - command-r
    #       - command-r-03-2024
    #       - command-r-08-2024
    #       - command-r-plus
    #       - command-r-plus-04-2024
    #       - command-r-plus-08-2024
    #       - command-r-plus-v1
    #       - command-r-v1
    #       - command-r7b-12-2024
    #       - command-text-v14
    #       - computer-use-preview
    #       - computer-use-preview-2025-03-11
    #       - davinci-002
    #       - deepcoder-14b-preview
    #       - deephermes-3-llama-3-8b-preview
    #       - deephermes-3-mistral-24b-preview
    #       - deepseek-chat
    #       - deepseek-chat-v3-0324
    #       - deepseek-coder
    #       - deepseek-prover-v2
    #       - deepseek-r1
    #       - deepseek-r1-distill-llama-70b
    #       - deepseek-r1-distill-llama-8b
    #       - deepseek-r1-distill-qwen-1.5b
    #       - deepseek-r1-distill-qwen-14b
    #       - deepseek-r1-distill-qwen-32b
    #       - deepseek-r1-zero
    #       - deepseek-r1t-chimera
    #       - deepseek-reasoner
    #       - deepseek-v3-base
    #       - devstral-small
    #       - dolphin-2.6-mixtral-8x7b
    #       - dolphin-2.9.1-llama-3-70b
    #       - dolphin-mixtral-8x22b
    #       - dolphin3.0-mistral-24b
    #       - dolphin3.0-r1-mistral-24b
    #       - eu.amazon.nova-lite-v1:0
    #       - eva-llama-3.33-70b
    #       - eva-qwen-2.5-32b
    #       - eva-qwen-2.5-72b
    #       - fimbulvetr-11b-v2
    #       - gemini-1.5-flash
    #       - gemini-1.5-flash-8b
    #       - gemini-1.5-flash-8b-latest
    #       - gemini-1.5-flash-latest
    #       - gemini-1.5-pro
    #       - gemini-1.5-pro-latest
    #       - gemini-2.0-flash
    #       - gemini-2.0-flash-001
    #       - gemini-2.0-flash-exp
    #       - gemini-2.0-flash-lite
    #       - gemini-2.0-flash-lite-001
    #       - gemini-2.0-flash-lite-preview-02-05
    #       - gemini-2.5-flash
    #       - gemini-2.5-flash-preview
    #       - gemini-2.5-flash-preview-04-17
    #       - gemini-2.5-flash-preview-05-20
    #       - gemini-2.5-pro
    #       - gemini-2.5-pro-exp-03-25
    #       - gemini-2.5-pro-preview
    #       - gemini-2.5-pro-preview-03-25
    #       - gemini-2.5-pro-preview-05-06
    #       - gemini-flash-1.5
    #       - gemini-flash-1.5-8b
    #       - gemini-flash-1.5-8b-exp
    #       - gemini-pro
    #       - gemini-pro-1.5
    #       - gemini-pro-vision
    #       - gemma-1.1-7b-it
    #       - gemma-2
    #       - gemma-2-27b-it
    #       - gemma-2-9b-it
    #       - gemma-2b-it
    #       - gemma-3
    #       - gemma-3-12b-it
    #       - gemma-3-1b-it
    #       - gemma-3-27b-it
    #       - gemma-3-4b-it
    #       - gemma2-9b-it
    #       - glm-4-32b
    #       - glm-4-9b
    #       - glm-z1-32b
    #       - glm-z1-9b
    #       - glm-z1-rumination-32b
    #       - goliath-120b
    #       - gpt-3.5-turbo
    #       - gpt-3.5-turbo-0125
    #       - gpt-3.5-turbo-0613
    #       - gpt-3.5-turbo-1106
    #       - gpt-3.5-turbo-16k
    #       - gpt-3.5-turbo-16k-0613
    #       - gpt-3.5-turbo-instruct
    #       - gpt-3.5-turbo-instruct-0914
    #       - gpt-35-turbo
    #       - gpt-35-turbo-16k
    #       - gpt-4
    #       - gpt-4-0125-preview
    #       - gpt-4-0314
    #       - gpt-4-0613
    #       - gpt-4-1106-preview
    #       - gpt-4-1106-vision-preview
    #       - gpt-4-32k
    #       - gpt-4-32k-0314
    #       - gpt-4-turbo
    #       - gpt-4-turbo-2024-04-09
    #       - gpt-4-turbo-preview
    #       - gpt-4-vision-preview
    #       - gpt-4.1
    #       - gpt-4.1-2025-04-14
    #       - gpt-4.1-mini
    #       - gpt-4.1-mini-2025-04-14
    #       - gpt-4.1-nano
    #       - gpt-4.1-nano-2025-04-14
    #       - gpt-4.5-preview
    #       - gpt-4.5-preview-2025-02-27
    #       - gpt-4o
    #       - gpt-4o-2024-05-13
    #       - gpt-4o-2024-08-06
    #       - gpt-4o-2024-11-20
    #       - gpt-4o-audio-preview
    #       - gpt-4o-audio-preview-2024-10-01
    #       - gpt-4o-audio-preview-2024-12-17
    #       - gpt-4o-mini
    #       - gpt-4o-mini-2024-07-18
    #       - gpt-4o-mini-audio-preview
    #       - gpt-4o-mini-audio-preview-2024-12-17
    #       - gpt-4o-mini-realtime-preview
    #       - gpt-4o-mini-realtime-preview-2024-12-17
    #       - gpt-4o-mini-search-preview
    #       - gpt-4o-mini-search-preview-2025-03-11
    #       - gpt-4o-mini-transcribe
    #       - gpt-4o-realtime-preview
    #       - gpt-4o-realtime-preview-2024-10-01
    #       - gpt-4o-realtime-preview-2024-12-17
    #       - gpt-4o-search-preview
    #       - gpt-4o-search-preview-2025-03-11
    #       - gpt-4o-transcribe
    #       - gpt-image-1
    #       - grok-2
    #       - grok-2-1212
    #       - grok-2-latest
    #       - grok-2-vision
    #       - grok-2-vision-1212
    #       - grok-2-vision-latest
    #       - grok-3
    #       - grok-3-beta
    #       - grok-3-mini-beta
    #       - grok-beta
    #       - grok-vision-beta
    #       - hermes-2-pro-llama-3-8b
    #       - hermes-3-llama-3.1-405b
    #       - hermes-3-llama-3.1-70b
    #       - inflection-3-pi
    #       - inflection-3-productivity
    #       - internvl3-14b
    #       - internvl3-2b
    #       - j2-mid
    #       - j2-ultra
    #       - jamba-1-5-large-v1
    #       - jamba-1-5-mini-v1
    #       - jamba-1.6-large
    #       - jamba-1.6-mini
    #       - jamba-instruct
    #       - jamba-instruct-v1
    #       - kimi-vl-a3b-thinking
    #       - l3-euryale-70b
    #       - l3-lunaris-8b
    #       - l3.1-euryale-70b
    #       - l3.3-electra-r1-70b
    #       - l3.3-euryale-70b
    #       - large-context
    #       - large-latest
    #       - learnlm-1.5-pro-experimental
    #       - lfm-3b
    #       - lfm-40b
    #       - lfm-7b
    #       - llama-2-70b-chat
    #       - llama-3-2-large
    #       - llama-3-2-small
    #       - llama-3-70b-instruct
    #       - llama-3-8b-instruct
    #       - llama-3-lumimaid-70b
    #       - llama-3-lumimaid-8b
    #       - llama-3.1-405b
    #       - llama-3.1-405b-instruct
    #       - llama-3.1-70b-instruct
    #       - llama-3.1-8b-instant
    #       - llama-3.1-8b-instruct
    #       - llama-3.1-lumimaid-70b
    #       - llama-3.1-lumimaid-8b
    #       - llama-3.1-nemotron-70b-instruct
    #       - llama-3.1-nemotron-ultra-253b-v1
    #       - llama-3.1-sonar-large-128k-online
    #       - llama-3.1-sonar-small-128k-online
    #       - llama-3.1-swallow-70b-instruct-v0.3
    #       - llama-3.2-11b-vision-instruct
    #       - llama-3.2-1b-instruct
    #       - llama-3.2-3b-instruct
    #       - llama-3.2-90b-vision-instruct
    #       - llama-3.3-70b-instruct
    #       - llama-3.3-70b-versatile
    #       - llama-3.3-8b-instruct
    #       - llama-3.3-nemotron-super-49b-v1
    #       - llama-4-maverick
    #       - llama-4-scout
    #       - llama-guard-2-8b
    #       - llama-guard-3-8b
    #       - llama-guard-4-12b
    #       - llama2-13b-chat-v1
    #       - llama2-70b-chat-v1
    #       - llama3-1-405b-instruct-v1
    #       - llama3-1-405b-instruct-v1:0
    #       - llama3-1-70b-instruct-v1
    #       - llama3-1-70b-instruct-v1:0
    #       - llama3-1-8b-instruct-v1
    #       - llama3-1-8b-instruct-v1:0
    #       - llama3-2-11b-instruct-v1
    #       - llama3-2-1b-instruct-v1
    #       - llama3-2-3b-instruct-v1
    #       - llama3-2-90b-instruct-v1
    #       - llama3-3-70b-instruct-v1
    #       - llama3-70b-8192
    #       - llama3-70b-instruct-v1
    #       - llama3-70b-instruct-v1:0
    #       - llama3-8b-8192
    #       - llama3-8b-instruct-v1
    #       - llama3-8b-instruct-v1:0
    #       - llama3.1-typhoon2-70b-instruct
    #       - llama3.1-typhoon2-8b-instruct
    #       - llama4-maverick-17b-instruct-v1
    #       - llama4-scout-17b-instruct-v1
    #       - llemma_7b
    #       - lzlv_70b_fp16_hf
    #       - maestro-reasoning
    #       - magnum-72b
    #       - magnum-v2-72b
    #       - magnum-v4-72b
    #       - mai-ds-r1
    #       - medium
    #       - mercury-coder-small-beta
    #       - meta-llama-3.1-8b-instruct
    #       - meta-llama-llama-2-70b-hf
    #       - meta.llama3-1-405b-instruct-v1:0
    #       - meta.llama3-1-70b-instruct-v1:0
    #       - meta.llama3-1-8b-instruct-v1:0
    #       - midnight-rose-70b
    #       - minimax-01
    #       - ministral-3b
    #       - ministral-8b
    #       - mistral-7b-instruct
    #       - mistral-7b-instruct-v0
    #       - mistral-7b-instruct-v0.1
    #       - mistral-7b-instruct-v0.2
    #       - mistral-7b-instruct-v0.3
    #       - mistral-large
    #       - mistral-large-2402
    #       - mistral-large-2402-v1
    #       - mistral-large-2407
    #       - mistral-large-2411
    #       - mistral-large-latest
    #       - mistral-medium
    #       - mistral-medium-2312
    #       - mistral-medium-3
    #       - mistral-medium-latest
    #       - mistral-nemo
    #       - mistral-saba
    #       - mistral-saba-latest
    #       - mistral-small
    #       - mistral-small-2402-v1
    #       - mistral-small-24b-instruct-2501
    #       - mistral-small-3.1-24b-instruct
    #       - mistral-small-latest
    #       - mistral-tiny
    #       - mixtral
    #       - mixtral-8x22b-instruct
    #       - mixtral-8x7b
    #       - mixtral-8x7b-instruct
    #       - mixtral-8x7b-instruct-v0
    #       - mn-celeste-12b
    #       - mn-inferor-12b
    #       - mn-starcannon-12b
    #       - molmo-7b-d
    #       - moonlight-16b-a3b-instruct
    #       - multimodal
    #       - mythalion-13b
    #       - mythomax
    #       - mythomax-l2-13b
    #       - noromaid-20b
    #       - nous-hermes-2-mixtral-8x7b-dpo
    #       - nous-hermes-2-vision-7b
    #       - nova-canvas-v1
    #       - nova-lite-v1
    #       - nova-micro-v1
    #       - nova-premier-v1
    #       - nova-pro-v1
    #       - nova-reel-v1
    #       - nova-sonic-v1
    #       - o1
    #       - o1-2024-12-17
    #       - o1-mini
    #       - o1-mini-2024-09-12
    #       - o1-preview
    #       - o1-preview-2024-09-12
    #       - o1-pro
    #       - o1-pro-2025-03-19
    #       - o3
    #       - o3-2025-04-16
    #       - o3-mini
    #       - o3-mini-2025-01-31
    #       - o3-mini-high
    #       - o4-mini
    #       - o4-mini-2025-04-16
    #       - o4-mini-high
    #       - olmo-7b-instruct
    #       - olympiccoder-32b
    #       - omni-moderation-2024-09-26
    #       - omni-moderation-latest
    #       - open-codestral-mamba
    #       - open-mistral-7b
    #       - open-mistral-nemo
    #       - open-mistral-nemo-2407
    #       - open-mixtral-8x22b
    #       - open-mixtral-8x7b
    #       - openchat-3.6-8b
    #       - openchat_3.5
    #       - openhands-lm-32b-v0.1
    #       - palm-2-chat-bison
    #       - palm-2-chat-bison-32k
    #       - palm-2-codechat-bison
    #       - palm-2-codechat-bison-32k
    #       - phi-3-medium-128k-instruct
    #       - phi-3-mini-128k-instruct
    #       - phi-3.5-mini-128k-instruct
    #       - phi-4
    #       - phi-4-multimodal-instruct
    #       - phi-4-reasoning
    #       - phi-4-reasoning-plus
    #       - pixtral-12b
    #       - pixtral-large-2411
    #       - pixtral-large-2502-v1
    #       - pixtral-large-latest
    #       - premium
    #       - premium-coding
    #       - qvq-72b-preview
    #       - qwen-2-5-large
    #       - qwen-2-72b-instruct
    #       - qwen-2-large
    #       - qwen-2-small
    #       - qwen-2-vl-7b-instruct
    #       - qwen-2.5-72b-instruct
    #       - qwen-2.5-7b-instruct
    #       - qwen-2.5-coder-32b-instruct
    #       - qwen-2.5-vl-72b-instruct
    #       - qwen-2.5-vl-7b-instruct
    #       - qwen-max
    #       - qwen-plus
    #       - qwen-turbo
    #       - qwen-vl-max
    #       - qwen-vl-plus
    #       - qwen2.5-coder-7b-instruct
    #       - qwen2.5-vl-32b-instruct
    #       - qwen2.5-vl-3b-instruct
    #       - qwen2.5-vl-72b-instruct
    #       - qwen3-0.6b-04-28
    #       - qwen3-1.7b
    #       - qwen3-14b
    #       - qwen3-235b-a22b
    #       - qwen3-30b-a3b
    #       - qwen3-32b
    #       - qwen3-4b
    #       - qwen3-8b
    #       - qwerky-72b
    #       - qwq-32b
    #       - qwq-32b-arliai-rpr-v1
    #       - qwq-32b-preview
    #       - r1-1776
    #       - r1-v1
    #       - reka-flash-3
    #       - remm-slerp-l2-13b
    #       - rocinante-12b
    #       - scb10x-llama3-1-typhoon2-70b-instruct
    #       - scb10x-llama3-1-typhoon2-8b-instruct
    #       - shisa-v2-llama3.3-70b
    #       - skyfall-36b-v2
    #       - small
    #       - sonar
    #       - sonar-deep-research
    #       - sonar-pro
    #       - sonar-reasoning
    #       - sonar-reasoning-pro
    #       - sorcererlm-8x22b
    #       - spotlight
    #       - starcoder2-15b-instruct-v0.1
    #       - text-babbage-002
    #       - text-davinci-002
    #       - tiny
    #       - titan-text-express-v1
    #       - titan-text-lite-v1
    #       - titan-text-premier-v1
    #       - titan-tg1-large
    #       - toppy-m-7b
    #       - tts-1
    #       - ui-tars-72b
    #       - ultra-fast
    #       - unslopnemo-12b
    #       - virtuoso-large
    #       - virtuoso-medium-v2
    #       - weaver
    #       - wizardlm-2-8x22b
    #       - yi-large
    #       - yi-vision
    #       - zephyr-7b-beta
    #     fetch: false
    #   titleConvo: true
    #   titleModel: "claude-3-haiku"
    #   summarize: false
    #   summaryModel: "claude-3-haiku"
    #   modelDisplayLabel: "APIpie"

    # # cohere
    # # Model list: https://dashboard.cohere.com/playground/chat
    # - name: "cohere"
    #   apiKey: "user_provided"
    #   baseURL: "https://api.cohere.ai/v1"
    #   models:
    #     default:
    #       - c4ai-aya-expanse-32b
    #       - c4ai-aya-vision-32b
    #       - command
    #       - command-a-03-2025
    #       - command-light-nightly
    #       - command-nightly
    #       - command-r
    #       - command-r-08-2024
    #       - command-r-plus-08-2024
    #       - command-r7b-12-2024
    #       - command-r7b-arabic-02-2025
    #     fetch: false
    #   modelDisplayLabel: "cohere"
    #   titleModel: "command"
    #   dropParams:
    #     - "stop"
    #     - "user"
    #     - "frequency_penalty"
    #     - "presence_penalty"
    #     - "temperature"
    #     - "top_p"

    # # deepseek
    # # https://platform.deepseek.com/api_keys
    # # Model list: https://platform.deepseek.com/api-docs/pricing
    # - name: "deepseek"
    #   apiKey: "user_provided"
    #   baseURL: "https://api.deepseek.com"
    #   models:
    #     default:
    #       - deepseek-chat
    #       - deepseek-reasoner
    #     fetch: false
    #   titleConvo: true
    #   titleModel: "deepseek-chat"
    #   summarize: false
    #   summaryModel: "deepseek-chat"
    #   modelDisplayLabel: "DeepSeek"

    # # Fireworks.ai
    # # Models: https://fireworks.ai/models?show=Serverless
    # - name: "Fireworks"
    #   apiKey: "user_provided"
    #   baseURL: "https://api.fireworks.ai/inference/v1"
    #   models:
    #     default:
    #       - accounts/fireworks/models/deepseek-r1
    #       - accounts/fireworks/models/deepseek-r1-basic
    #       - accounts/fireworks/models/deepseek-v3
    #       - accounts/fireworks/models/deepseek-v3-0324
    #       - accounts/fireworks/models/firesearch-ocr-v6
    #       - accounts/fireworks/models/llama-guard-3-8b
    #       - accounts/fireworks/models/llama-v3p1-405b-instruct
    #       - accounts/fireworks/models/llama-v3p1-405b-instruct-long
    #       - accounts/fireworks/models/llama-v3p1-70b-instruct
    #       - accounts/fireworks/models/llama-v3p1-8b-instruct
    #       - accounts/fireworks/models/llama-v3p3-70b-instruct
    #       - accounts/fireworks/models/llama4-maverick-instruct-basic
    #       - accounts/fireworks/models/llama4-scout-instruct-basic
    #       - accounts/fireworks/models/mixtral-8x22b-instruct
    #       - accounts/fireworks/models/qwen2-vl-72b-instruct
    #       - accounts/fireworks/models/qwen2p5-72b-instruct
    #       - accounts/fireworks/models/qwen2p5-vl-32b-instruct
    #       - accounts/fireworks/models/qwen3-235b-a22b
    #       - accounts/fireworks/models/qwen3-30b-a3b
    #       - accounts/fireworks/models/qwq-32b
    #       - accounts/instacart/models/srl-finetune-0417-debug
    #       - accounts/perplexity/models/r1-1776
    #       - accounts/sentientfoundation/models/dobby-unhinged-llama-3-3-70b-new
    #     fetch: false
    #   titleConvo: true
    #   titleModel: "accounts/fireworks/models/llama-v2-7b-chat"
    #   summarize: false
    #   summaryModel: "accounts/fireworks/models/llama-v2-7b-chat"
    #   forcePrompt: false
    #   modelDisplayLabel: "Fireworks"
    #   dropParams:
    #     - "user"

    # # GitHub 
    # # Models: https://models.inference.ai.azure.com/models
    # - name: "Github Models"
    #   iconURL: https://github.githubassets.com/assets/GitHub-Mark-ea2971cee799.png
    #   apiKey: "user_provided"
    #   baseURL: "https://models.inference.ai.azure.com"
    #   models:
    #     default:
    #       - AI21-Jamba-Instruct
    #       - Cohere-command-r
    #       - Cohere-command-r-plus
    #       - Cohere-embed-v3-english
    #       - Cohere-embed-v3-multilingual
    #       - Meta-Llama-3-70B-Instruct
    #       - Meta-Llama-3-8B-Instruct
    #       - Meta-Llama-3.1-405B-Instruct
    #       - Meta-Llama-3.1-70B-Instruct
    #       - Meta-Llama-3.1-8B-Instruct
    #       - Mistral-Nemo
    #       - Mistral-large-2407
    #       - Mistral-small
    #       - Phi-3-medium-128k-instruct
    #       - Phi-3-medium-4k-instruct
    #       - Phi-3-mini-128k-instruct
    #       - Phi-3-mini-4k-instruct
    #       - Phi-3-small-128k-instruct
    #       - Phi-3-small-8k-instruct
    #       - Phi-3.5-mini-instruct
    #       - gpt-4o
    #       - gpt-4o-mini
    #       - text-embedding-3-large
    #       - text-embedding-3-small
    #     fetch: false
    #   titleConvo: true
    #   titleModel: "gpt-4o-mini"

    # # glhf.chat 
    # # Model list (auth header required): https://glhf.chat/models
    # - name: "glhf.chat"
    #   iconURL: "https://glhf.chat/apple-touch-icon.png"
    #   apiKey: "user_provided"
    #   baseURL: "https://glhf.chat/api/openai/v1"
    #   models:
    #     default:
    #       - hf:NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO
    #       - hf:Qwen/QwQ-32B-Preview
    #       - hf:Qwen/Qwen2.5-72B-Instruct
    #       - hf:Qwen/Qwen2.5-7B-Instruct
    #       - hf:Qwen/Qwen2.5-Coder-32B-Instruct
    #       - hf:Qwen/Qwen3-235B-A22B
    #       - hf:accounts/fireworks/models/llama-v3p2-3b-instruct
    #       - hf:anthracite-org/magnum-v4-12b
    #       - hf:deepseek-ai/DeepSeek-R1
    #       - hf:deepseek-ai/DeepSeek-R1-Distill-Llama-70B
    #       - hf:deepseek-ai/DeepSeek-V3
    #       - hf:deepseek-ai/DeepSeek-V3-0324
    #       - hf:google/gemma-2-27b-it
    #       - hf:google/gemma-2-9b-it
    #       - hf:huihui-ai/Llama-3.3-70B-Instruct-abliterated
    #       - hf:meta-llama/Llama-3.1-405B-Instruct
    #       - hf:meta-llama/Llama-3.1-70B-Instruct
    #       - hf:meta-llama/Llama-3.1-8B-Instruct
    #       - hf:meta-llama/Llama-3.2-11B-Vision-Instruct
    #       - hf:meta-llama/Llama-3.2-3B-Instruct
    #       - hf:meta-llama/Llama-3.2-3B-Instruct-Turbo
    #       - hf:meta-llama/Llama-3.2-90B-Vision-Instruct
    #       - hf:meta-llama/Llama-3.3-70B-Instruct
    #       - hf:meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8
    #       - hf:meta-llama/Llama-4-Scout-17B-16E-Instruct
    #       - hf:mistralai/Mistral-7B-Instruct-v0.3
    #       - hf:mistralai/Mixtral-8x22B-Instruct-v0.1
    #       - hf:mistralai/Mixtral-8x7B-Instruct-v0.1
    #       - hf:nvidia/Llama-3.1-Nemotron-70B-Instruct-HF
    #       - hf:upstage/SOLAR-10.7B-Instruct-v1.0
    #     fetch: false
    #   titleConvo: true
    #   titleModel: "current_model"

    # # groq
    # # Model list: https://console.groq.com/settings/limits
    # - name: "groq"
    #   apiKey: "user_provided"
    #   baseURL: "https://api.groq.com/openai/v1/"
    #   models:
    #     default:
    #       - allam-2-7b
    #       - compound-beta
    #       - compound-beta-mini
    #       - deepseek-r1-distill-llama-70b
    #       - gemma2-9b-it
    #       - llama-3.1-8b-instant
    #       - llama-3.3-70b-versatile
    #       - llama-guard-3-8b
    #       - llama3-70b-8192
    #       - llama3-8b-8192
    #       - meta-llama/llama-4-maverick-17b-128e-instruct
    #       - meta-llama/llama-4-scout-17b-16e-instruct
    #       - meta-llama/llama-guard-4-12b
    #       - mistral-saba-24b
    #       - playai-tts
    #       - playai-tts-arabic
    #       - qwen-qwq-32b
    #     fetch: false
    #   titleConvo: true
    #   titleModel: "mixtral-8x7b-32768"
    #   modelDisplayLabel: "groq"

    # # HuggingFace
    # # https://huggingface.co/settings/tokens
    # - name: 'HuggingFace'
    #   apiKey: 'user_provided'
    #   baseURL: 'https://api-inference.huggingface.co/v1'
    #   models:
    #     default:
    #       - AIDC-AI/Marco-o1
    #       - CohereLabs/c4ai-command-r-plus
    #       - CohereLabs/c4ai-command-r-v01
    #       - HuggingFaceH4/zephyr-7b-alpha
    #       - HuggingFaceH4/zephyr-7b-beta
    #       - HuggingFaceTB/SmolLM2-1.7B-Instruct
    #       - Intel/neural-chat-7b-v3-1
    #       - MiniMaxAI/MiniMax-Text-01
    #       - NexaAIDev/Octopus-v2
    #       - Open-Orca/Mistral-7B-OpenOrca
    #       - PygmalionAI/pygmalion-6b
    #       - Qwen/QwQ-32B
    #       - Qwen/QwQ-32B-Preview
    #       - Qwen/Qwen2-72B-Instruct
    #       - Qwen/Qwen2-7B-Instruct
    #       - Qwen/Qwen2.5-72B-Instruct
    #       - Qwen/Qwen2.5-7B-Instruct
    #       - Qwen/Qwen2.5-Coder-32B-Instruct
    #       - Qwen/Qwen3-235B-A22B
    #       - Qwen/Qwen3-30B-A3B
    #       - TinyLlama/TinyLlama-1.1B-Chat-v1.0
    #       - agentica-org/DeepCoder-14B-Preview
    #       - berkeley-nest/Starling-LM-7B-alpha
    #       - cognitivecomputations/dolphin-2.5-mixtral-8x7b
    #       - databricks/dbrx-base
    #       - databricks/dbrx-instruct
    #       - deepseek-ai/DeepSeek-Coder-V2-Instruct
    #       - deepseek-ai/DeepSeek-Prover-V2-671B
    #       - deepseek-ai/DeepSeek-R1
    #       - deepseek-ai/DeepSeek-R1-Distill-Llama-70B
    #       - deepseek-ai/DeepSeek-R1-Distill-Llama-8B
    #       - deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
    #       - deepseek-ai/DeepSeek-R1-Distill-Qwen-32B
    #       - deepseek-ai/DeepSeek-R1-Distill-Qwen-7B
    #       - deepseek-ai/DeepSeek-R1-Zero
    #       - deepseek-ai/DeepSeek-V2.5
    #       - deepseek-ai/DeepSeek-V3
    #       - deepseek-ai/DeepSeek-V3-0324
    #       - google/gemma-2-2b-it
    #       - google/gemma-2-9b-it
    #       - google/gemma-2b-it
    #       - google/gemma-7b-it
    #       - gradientai/Llama-3-8B-Instruct-Gradient-1048k
    #       - jinaai/ReaderLM-v2
    #       - jinaai/reader-lm-1.5b
    #       - manycore-research/SpatialLM-Llama-1B
    #       - mattshumer/Reflection-Llama-3.1-70B
    #       - meta-llama/Llama-2-13b-chat-hf
    #       - meta-llama/Llama-2-70b-chat-hf
    #       - meta-llama/Llama-2-7b-chat-hf
    #       - meta-llama/Llama-3.1-405B-Instruct
    #       - meta-llama/Llama-3.1-70B-Instruct
    #       - meta-llama/Llama-3.1-8B-Instruct
    #       - meta-llama/Llama-3.2-1B-Instruct
    #       - meta-llama/Llama-3.2-3B-Instruct
    #       - meta-llama/Llama-3.3-70B-Instruct
    #       - meta-llama/Meta-Llama-3-70B-Instruct
    #       - meta-llama/Meta-Llama-3-8B-Instruct
    #       - microsoft/Phi-3-mini-128k-instruct
    #       - microsoft/Phi-3-mini-4k-instruct
    #       - microsoft/Phi-3-vision-128k-instruct
    #       - microsoft/Phi-3.5-MoE-instruct
    #       - microsoft/Phi-3.5-mini-instruct
    #       - microsoft/bitnet-b1.58-2B-4T
    #       - microsoft/phi-4
    #       - mistralai/Codestral-22B-v0.1
    #       - mistralai/Mistral-7B-Instruct-v0.1
    #       - mistralai/Mistral-7B-Instruct-v0.2
    #       - mistralai/Mistral-7B-Instruct-v0.3
    #       - mistralai/Mistral-Nemo-Instruct-2407
    #       - mistralai/Mistral-Small-24B-Instruct-2501
    #       - mistralai/Mixtral-8x22B-Instruct-v0.1
    #       - mistralai/Mixtral-8x7B-Instruct-v0.1
    #       - nvidia/Llama-3.1-Nemotron-70B-Instruct-HF
    #       - nvidia/Llama3-ChatQA-1.5-8B
    #       - openchat/openchat_3.5
    #       - perplexity-ai/r1-1776
    #       - shenzhi-wang/Llama3-8B-Chinese-Chat
    #       - teknium/OpenHermes-2.5-Mistral-7B
    #       - tiiuae/falcon-180B-chat
    #       - tiiuae/falcon-7b-instruct
    #       - unsloth/DeepSeek-R1-GGUF
    #       - upstage/SOLAR-10.7B-Instruct-v1.0
    #     fetch: false
    #   titleConvo: true
    #   titleModel: "NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO"
    #   dropParams:
    #     - "top_p"

    # # Hyperbolic
    # # https://app.hyperbolic.xyz/models
    # - name: 'Hyperbolic'
    #   iconURL: "https://app.hyperbolic.xyz/icon.svg"
    #   apiKey: 'user_provided'
    #   baseURL: 'https://api.hyperbolic.xyz/v1/'
    #   models:
    #     default:
    #       - NousResearch/Hermes-3-Llama-3.1-70B
    #       - Qwen/QwQ-32B
    #       - Qwen/QwQ-32B-Preview
    #       - Qwen/Qwen2.5-72B-Instruct
    #       - Qwen/Qwen2.5-Coder-32B-Instruct
    #       - SDXL1.0-base
    #       - deepseek-ai/DeepSeek-R1
    #       - deepseek-ai/DeepSeek-V3
    #       - deepseek-ai/DeepSeek-V3-0324
    #       - meta-llama/Llama-3.2-3B-Instruct
    #       - meta-llama/Llama-3.3-70B-Instruct
    #       - meta-llama/Meta-Llama-3-70B-Instruct
    #       - meta-llama/Meta-Llama-3.1-405B
    #       - meta-llama/Meta-Llama-3.1-405B-FP8
    #       - meta-llama/Meta-Llama-3.1-405B-Instruct
    #       - meta-llama/Meta-Llama-3.1-70B-Instruct
    #       - meta-llama/Meta-Llama-3.1-8B-Instruct
    #     fetch: false
    #   titleConvo: true
    #   titleModel: "meta-llama/Meta-Llama-3.1-8B-Instruct"
    #   modelDisplayLabel: "Hyperbolic"

    # # kluster.ai
    # # https://platform.kluster.ai/apikeys
    # - name: "Kluster"
    #   iconURL: "https://platform.kluster.ai/cropped-fav-1-144x144.png"
    #   apiKey: "user_provided"
    #   baseURL: "https://api.kluster.ai/v1/"
    #   models:
    #     default:
    #       - Qwen/Qwen2.5-VL-7B-Instruct
    #       - Qwen/Qwen3-235B-A22B-FP8
    #       - deepseek-ai/DeepSeek-R1
    #       - deepseek-ai/DeepSeek-V3-0324
    #       - google/gemma-3-27b-it
    #       - klusterai/Meta-Llama-3.1-8B-Instruct-Turbo
    #       - klusterai/Meta-Llama-3.3-70B-Instruct-Turbo
    #       - meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8
    #       - meta-llama/Llama-4-Scout-17B-16E-Instruct
    #       - mistralai/Mistral-Nemo-Instruct-2407
    #     fetch: false
    #   titleConvo: true
    #   titleModel: 'klusterai/Meta-Llama-3.1-8B-Instruct-Turbo'
    #   modelDisplayLabel: 'Kluster'

    # # Mistral AI API
    # # Model list: https://docs.mistral.ai/getting-started/models/
    # - name: "Mistral"
    #   apiKey: "user_provided"
    #   baseURL: "https://api.mistral.ai/v1"
    #   models:
    #     default:
    #       - codestral-2405
    #       - codestral-2411-rc5
    #       - codestral-2412
    #       - codestral-2501
    #       - codestral-latest
    #       - codestral-mamba-2407
    #       - codestral-mamba-latest
    #       - devstral-small-2505
    #       - devstral-small-latest
    #       - ministral-3b-2410
    #       - ministral-3b-latest
    #       - ministral-8b-2410
    #       - ministral-8b-latest
    #       - mistral-embed
    #       - mistral-large-2402
    #       - mistral-large-2407
    #       - mistral-large-2411
    #       - mistral-large-latest
    #       - mistral-large-pixtral-2411
    #       - mistral-medium
    #       - mistral-medium-2312
    #       - mistral-medium-2505
    #       - mistral-medium-latest
    #       - mistral-moderation-2411
    #       - mistral-moderation-latest
    #       - mistral-ocr-2503
    #       - mistral-ocr-2505
    #       - mistral-ocr-latest
    #       - mistral-saba-2502
    #       - mistral-saba-latest
    #       - mistral-small
    #       - mistral-small-2312
    #       - mistral-small-2402
    #       - mistral-small-2409
    #       - mistral-small-2501
    #       - mistral-small-2503
    #       - mistral-small-latest
    #       - mistral-tiny
    #       - mistral-tiny-2312
    #       - mistral-tiny-2407
    #       - mistral-tiny-latest
    #       - open-codestral-mamba
    #       - open-mistral-7b
    #       - open-mistral-nemo
    #       - open-mistral-nemo-2407
    #       - open-mixtral-8x22b
    #       - open-mixtral-8x22b-2404
    #       - open-mixtral-8x7b
    #       - pixtral-12b
    #       - pixtral-12b-2409
    #       - pixtral-12b-latest
    #       - pixtral-large-2411
    #       - pixtral-large-latest
    #     fetch: false
    #   titleConvo: true
    #   titleMethod: "completion"
    #   titleModel: "mistral-tiny"
    #   summarize: false
    #   summaryModel: "mistral-tiny"
    #   forcePrompt: false
    #   modelDisplayLabel: "Mistral"
    #   dropParams:
    #     - "stop"
    #     - "user"
    #     - "frequency_penalty"
    #     - "presence_penalty"

    # # NanoGPT
    # # https://nano-gpt.com/api
    # # Model list: https://nano-gpt.com/api/models
    # - name: "NanoGPT"
    #   iconURL: "https://nano-gpt.com/logo.png"
    #   apiKey: "user_provided"
    #   baseURL: "https://nano-gpt.com/api/v1/"
    #   models:
    #     default:
    #       - EVA-UNIT-01/EVA-LLaMA-3.33-70B-v0.0
    #       - EVA-UNIT-01/EVA-LLaMA-3.33-70B-v0.1
    #       - EVA-UNIT-01/EVA-Qwen2.5-32B-v0.2
    #       - EVA-UNIT-01/EVA-Qwen2.5-72B-v0.2
    #       - Envoid/Llama-3.05-NT-Storybreaker-Ministral-70B
    #       - Envoid/Llama-3.05-Nemotron-Tenyxchat-Storybreaker-70B
    #       - GalrionSoftworks/MN-LooseCannon-12B-v1
    #       - Gryphe/MythoMax-L2-13b
    #       - Infermatic/MN-12B-Inferor-v0.0
    #       - LatitudeGames/Wayfarer-Large-70B-Llama-3.3
    #       - Llama-3.3+(3.1v3.3)-70B-Hanami-x1
    #       - Llama-3.3+(3.1v3.3)-70B-WhiteRabbitNeo-2
    #       - Llama-3.3+(3v3.3)-70B-TenyxChat-DaybreakStorywriter
    #       - Llama-3.3+3.1-70B-ArliAI-RPMax-v1.3
    #       - Llama-3.3-70B-Anubis-v1
    #       - Llama-3.3-70B-ArliAI-RPMax-v1.4
    #       - Llama-3.3-70B-Cu-Mai-R1
    #       - Llama-3.3-70B-Electra-R1
    #       - Llama-3.3-70B-Electranova-v1.0
    #       - Llama-3.3-70B-Fallen-R1-v1
    #       - Llama-3.3-70B-Legion-V2.1
    #       - Llama-3.3-70B-Magnum-v4-SE
    #       - Llama-3.3-70B-MiraiFanfare
    #       - Llama-3.3-70B-Vulpecula-R1
    #       - MarinaraSpaghetti/NemoMix-Unleashed-12B
    #       - Meta-Llama-3-1-405B-Instruct-FP8
    #       - Meta-Llama-3-1-8B-Instruct-FP8
    #       - Mistral-Nemo-12B-ArliAI-RPMax-v1.1
    #       - Mistral-Nemo-12B-ArliAI-RPMax-v1.2
    #       - Mistral-Nemo-12B-ArliAI-RPMax-v1.3
    #       - Mistral-Nemo-12B-Instruct-2407
    #       - Mistral-Nemo-12B-NemoMix-Unleashed
    #       - Mistral-Nemo-12B-SauerkrautLM
    #       - Mistral-Nemo-12B-Wayfarer
    #       - NeverSleep/Llama-3-Lumimaid-70B-v0.1
    #       - NeverSleep/Lumimaid-v0.2-70B
    #       - Nexusflow/Athene-V2-Chat
    #       - NousResearch/DeepHermes-3-Mistral-24B-Preview
    #       - QwQ-32B-ArliAI-RpR-v1
    #       - QwQ-32B-ArliAI-RpR-v2
    #       - QwQ-32B-ArliAI-RpR-v3
    #       - QwQ-32B-Snowdrop-v0
    #       - QwQ-32B-Snowdrop-v0-nothink
    #       - Qwen/QwQ-32B-Preview
    #       - Qwen/Qwen2.5-Coder-32B-Instruct
    #       - Qwen/Qwen3-8B
    #       - Qwen2.5-32B-Dazzling-Star-Aurora-32b-v0.0
    #       - Qwen2.5-32B-EVA-v0.2
    #       - Qwen2.5-72B-Instruct
    #       - Qwen3-32B
    #       - ReadyArt/The-Omega-Abomination-L-70B-v1.0
    #       - ReadyArt/The-Omega-Abomination-L-70B-v5.0
    #       - Salesforce/Llama-xLAM-2-70b-fc-r
    #       - Sao10K/L3-8B-Stheno-v3.2
    #       - Sao10K/L3.1-70B-Euryale-v2.2
    #       - Sao10K/L3.1-70B-Hanami-x1
    #       - Sao10K/L3.3-70B-Euryale-v2.3
    #       - Steelskull/L3.3-Cu-Mai-R1-70b
    #       - Steelskull/L3.3-Damascus-R1
    #       - Steelskull/L3.3-Electra-R1-70b
    #       - Steelskull/L3.3-MS-Evalebis-70b
    #       - Steelskull/L3.3-MS-Evayale-70B
    #       - Steelskull/L3.3-MS-Nevoria-70b
    #       - Steelskull/L3.3-Nevoria-R1-70b
    #       - TEE/deepseek-r1-70b
    #       - TEE/hermes-3-llama-3.1-70b
    #       - TEE/llama-3.3-70b-instruct
    #       - TEE/qwen-2.5-7b-instruct
    #       - THUDM/GLM-4-32B-0414
    #       - THUDM/GLM-4-9B-0414
    #       - THUDM/GLM-Z1-32B-0414
    #       - THUDM/GLM-Z1-9B-0414
    #       - THUDM/GLM-Z1-Rumination-32B-0414
    #       - TheDrummer/Anubis-70B-v1
    #       - TheDrummer/Cydonia-24B-v2
    #       - TheDrummer/Rocinante-12B-v1.1
    #       - TheDrummer/UnslopNemo-12B-v4.1
    #       - VongolaChouko/Starcannon-Unleashed-12B-v1.0
    #       - abacusai/Dracarys-72B-Instruct
    #       - agentica-org/DeepCoder-14B-Preview
    #       - aion-labs/aion-1.0
    #       - aion-labs/aion-1.0-mini
    #       - aion-labs/aion-rp-llama-3.1-8b
    #       - amazon/nova-lite-v1
    #       - amazon/nova-micro-v1
    #       - amazon/nova-pro-v1
    #       - anthracite-org/magnum-v2-72b
    #       - anthracite-org/magnum-v4-72b
    #       - anubis-pro-105b-v1
    #       - asi1-mini
    #       - azure-gpt-4-turbo
    #       - azure-gpt-4o
    #       - azure-gpt-4o-mini
    #       - azure-o1
    #       - azure-o3-mini
    #       - chatgpt-4o-latest
    #       - chatgpt-4o-latest-reasoner
    #       - claude-3-5-haiku-20241022
    #       - claude-3-5-sonnet-20240620
    #       - claude-3-5-sonnet-20241022
    #       - claude-3-7-sonnet-20250219
    #       - claude-3-7-sonnet-reasoner
    #       - claude-3-7-sonnet-thinking
    #       - claude-3-7-sonnet-thinking:1024
    #       - claude-3-7-sonnet-thinking:128000
    #       - claude-3-7-sonnet-thinking:32768
    #       - claude-3-7-sonnet-thinking:8192
    #       - claude-3-opus-20240229
    #       - claude-opus-4-20250514
    #       - claude-opus-4-thinking
    #       - claude-opus-4-thinking:1024
    #       - claude-opus-4-thinking:128000
    #       - claude-opus-4-thinking:32768
    #       - claude-opus-4-thinking:8192
    #       - claude-sonnet-4-20250514
    #       - claude-sonnet-4-thinking
    #       - claude-sonnet-4-thinking:1024
    #       - claude-sonnet-4-thinking:128000
    #       - claude-sonnet-4-thinking:32768
    #       - claude-sonnet-4-thinking:8192
    #       - cognitivecomputations/dolphin-mixtral-8x22b
    #       - cohere/command-r
    #       - cohere/command-r-plus-08-2024
    #       - deepclaude
    #       - deepcogito/cogito-v1-preview-qwen-32B
    #       - deepseek-ai/DeepSeek-Prover-V2-671B
    #       - deepseek-ai/DeepSeek-R1-Zero
    #       - deepseek-chat
    #       - deepseek-chat-cheaper
    #       - deepseek-r1-llama-70b
    #       - deepseek-r1-nano
    #       - deepseek-r1-sambanova
    #       - deepseek-reasoner
    #       - deepseek-reasoner-cheaper
    #       - deepseek-v3-0324
    #       - dolphin-2.9.2-qwen2-72b
    #       - doubao-1-5-thinking-pro-250415
    #       - doubao-1-5-thinking-pro-vision-250415
    #       - doubao-1-5-thinking-vision-pro-250428
    #       - doubao-1.5-pro-256k
    #       - doubao-1.5-pro-32k
    #       - doubao-1.5-vision-pro-32k
    #       - ernie-4.5-8k-preview
    #       - ernie-4.5-turbo-128k
    #       - ernie-4.5-turbo-vl-32k
    #       - ernie-x1-32k
    #       - ernie-x1-32k-preview
    #       - ernie-x1-turbo-32k
    #       - eva-unit-01/eva-qwen-2.5-72b
    #       - failspy/Meta-Llama-3-70B-Instruct-abliterated-v3.5
    #       - featherless-ai/Qwerky-72B
    #       - free-model
    #       - gemini-2.0-flash-001
    #       - gemini-2.0-flash-exp-image-generation
    #       - gemini-2.0-flash-exp-search
    #       - gemini-2.0-flash-lite
    #       - gemini-2.0-flash-thinking-exp-01-21
    #       - gemini-2.0-flash-thinking-exp-1219
    #       - gemini-2.0-pro-exp-02-05
    #       - gemini-2.0-pro-reasoner
    #       - gemini-2.5-flash-preview-04-17
    #       - gemini-2.5-flash-preview-04-17:thinking
    #       - gemini-2.5-flash-preview-05-20
    #       - gemini-2.5-flash-preview-05-20:thinking
    #       - gemini-2.5-pro-exp-03-25
    #       - gemini-2.5-pro-preview-03-25
    #       - gemini-2.5-pro-preview-05-06
    #       - gemini-exp-1206
    #       - gemini-exp-1206
    #       - glm-4
    #       - glm-4-air
    #       - glm-4-air-0111
    #       - glm-4-airx
    #       - glm-4-flash
    #       - glm-4-long
    #       - glm-4-plus
    #       - glm-4-plus-0111
    #       - glm-z1-air
    #       - glm-z1-airx
    #       - glm-zero-preview
    #       - google/gemini-flash-1.5
    #       - gpt-3.5-turbo
    #       - gpt-4-turbo-preview
    #       - gpt-4.1-reasoner
    #       - gpt-4.5-preview
    #       - gpt-4.5-preview-2025-02-27
    #       - gpt-4o
    #       - gpt-4o-2024-08-06
    #       - gpt-4o-2024-11-20
    #       - gpt-4o-mini
    #       - gpt-4o-mini-search-preview
    #       - gpt-4o-reasoner
    #       - gpt-4o-search-preview
    #       - grok-3-beta
    #       - grok-3-fast-beta
    #       - grok-3-mini-beta
    #       - grok-3-mini-fast-beta
    #       - huihui-ai/DeepSeek-R1-Distill-Llama-70B-abliterated
    #       - huihui-ai/DeepSeek-R1-Distill-Qwen-32B-abliterated
    #       - huihui-ai/Llama-3.1-Nemotron-70B-Instruct-HF-abliterated
    #       - huihui-ai/Llama-3.3-70B-Instruct-abliterated
    #       - hunyuan-t1-latest
    #       - hunyuan-turbos-20250226
    #       - inflatebot/MN-12B-Mag-Mell-R1
    #       - inflection/inflection-3-pi
    #       - inflection/inflection-3-productivity
    #       - jamba-large-1.6
    #       - jamba-mini-1.6
    #       - kimi-latest
    #       - kimi-thinking-preview
    #       - learnlm-1.5-pro-experimental
    #       - mercury-coder-small
    #       - meta-llama/llama-3.1-8b-instruct
    #       - meta-llama/llama-3.2-3b-instruct
    #       - meta-llama/llama-3.2-90b-vision-instruct
    #       - meta-llama/llama-3.3-70b-instruct
    #       - meta-llama/llama-4-maverick
    #       - meta-llama/llama-4-scout
    #       - microsoft/MAI-DS-R1-FP8
    #       - microsoft/Phi-4-reasoning
    #       - microsoft/Phi-4-reasoning-plus
    #       - microsoft/wizardlm-2-8x22b
    #       - minimax/minimax-01
    #       - mistral-small-31-24b-instruct
    #       - mistralai/Mistral-Nemo-Instruct-2407
    #       - mistralai/mistral-7b-instruct
    #       - mistralai/mistral-large
    #       - mistralai/mistral-medium-3
    #       - mistralai/mistral-saba
    #       - mistralai/mistral-tiny
    #       - mlabonne/NeuralDaredevil-8B-abliterated
    #       - moonshotai/Kimi-VL-A3B-Thinking
    #       - nothingiisreal/L3.1-70B-Celeste-V0.1-BF16
    #       - nousresearch/hermes-3-llama-3.1-405b
    #       - nvidia/Llama-3.1-Nemotron-70B-Instruct-HF
    #       - nvidia/Llama-3.1-Nemotron-Ultra-253B-v1
    #       - nvidia/Llama-3.3-Nemotron-Super-49B-v1
    #       - o1
    #       - o1-mini
    #       - o1-preview
    #       - o3
    #       - o3-mini
    #       - o3-mini-high
    #       - o3-mini-low
    #       - o4-mini
    #       - o4-mini-high
    #       - open-r1/OlympicCoder-32B
    #       - open-r1/OlympicCoder-7b
    #       - openai/gpt-4.1
    #       - openai/gpt-4.1-mini
    #       - openai/gpt-4.1-nano
    #       - openai/o1-pro
    #       - phi-4-mini-instruct
    #       - phi-4-multimodal-instruct
    #       - qvq-max
    #       - qwen-long
    #       - qwen-max
    #       - qwen-plus
    #       - qwen-turbo
    #       - qwen/qwen-2.5-72b-instruct
    #       - qwen/qwen3-14b
    #       - qwen/qwen3-235b-a22b
    #       - qwen/qwen3-30b-a3b
    #       - qwen/qwen3-32b
    #       - qwen25-vl-72b-instruct
    #       - qwq-32b
    #       - r1-1776
    #       - raifle/sorcererlm-8x22b
    #       - shisa-ai/shisa-v2-llama3.3-70b
    #       - sonar
    #       - sonar-deep-research
    #       - sonar-pro
    #       - sonar-reasoning
    #       - sonar-reasoning-pro
    #       - soob3123/GrayLine-Qwen3-8B
    #       - soob3123/Veiled-Calla-12B
    #       - soob3123/amoral-gemma3-27B-v2
    #       - step-2-16k-exp
    #       - step-2-mini
    #       - step-r1-v-mini
    #       - thedrummer/skyfall-36b-v2
    #       - tngtech/DeepSeek-R1T-Chimera
    #       - undi95/remm-slerp-l2-13b
    #       - unsloth/gemma-3-12b-it
    #       - unsloth/gemma-3-1b-it
    #       - unsloth/gemma-3-27b-it
    #       - unsloth/gemma-3-4b-it
    #       - yi-34b-chat-0205
    #       - yi-34b-chat-200k
    #       - yi-large
    #       - yi-lightning
    #       - yi-medium-200k
    #     fetch: false
    #   titleConvo: true
    #   titleModel: "current_model"
    #   modelDisplayLabel: "NanoGPT"

    # # NVIDIA
    # # https://build.nvidia.com/explore/discover
    # - name: "Nvidia"
    #   iconURL: "https://raw.githubusercontent.com/LibreChat-AI/librechat-config-yaml/refs/heads/main/icons/nvidia.png"
    #   apiKey: "user_provided"
    #   baseURL: "https://integrate.api.nvidia.com/v1/"
    #   models:
    #     default:
    #       - 01-ai/yi-large
    #       - abacusai/dracarys-llama-3.1-70b-instruct
    #       - adept/fuyu-8b
    #       - ai21labs/jamba-1.5-large-instruct
    #       - ai21labs/jamba-1.5-mini-instruct
    #       - aisingapore/sea-lion-7b-instruct
    #       - baai/bge-m3
    #       - baichuan-inc/baichuan2-13b-chat
    #       - bigcode/starcoder2-15b
    #       - bigcode/starcoder2-7b
    #       - databricks/dbrx-instruct
    #       - deepseek-ai/deepseek-coder-6.7b-instruct
    #       - deepseek-ai/deepseek-r1
    #       - deepseek-ai/deepseek-r1-distill-llama-8b
    #       - deepseek-ai/deepseek-r1-distill-qwen-14b
    #       - deepseek-ai/deepseek-r1-distill-qwen-32b
    #       - deepseek-ai/deepseek-r1-distill-qwen-7b
    #       - google/codegemma-1.1-7b
    #       - google/codegemma-7b
    #       - google/deplot
    #       - google/gemma-2-27b-it
    #       - google/gemma-2-2b-it
    #       - google/gemma-2-9b-it
    #       - google/gemma-2b
    #       - google/gemma-3-12b-it
    #       - google/gemma-3-1b-it
    #       - google/gemma-3-27b-it
    #       - google/gemma-3-4b-it
    #       - google/gemma-7b
    #       - google/paligemma
    #       - google/recurrentgemma-2b
    #       - google/shieldgemma-9b
    #       - gotocompany/gemma-2-9b-cpt-sahabatai-instruct
    #       - ibm/granite-3.0-3b-a800m-instruct
    #       - ibm/granite-3.0-8b-instruct
    #       - ibm/granite-3.3-8b-instruct
    #       - ibm/granite-34b-code-instruct
    #       - ibm/granite-8b-code-instruct
    #       - ibm/granite-guardian-3.0-8b
    #       - igenius/colosseum_355b_instruct_16k
    #       - igenius/italia_10b_instruct_16k
    #       - institute-of-science-tokyo/llama-3.1-swallow-70b-instruct-v0.1
    #       - institute-of-science-tokyo/llama-3.1-swallow-8b-instruct-v0.1
    #       - marin/marin-8b-instruct
    #       - mediatek/breeze-7b-instruct
    #       - meta/codellama-70b
    #       - meta/llama-3.1-405b-instruct
    #       - meta/llama-3.1-70b-instruct
    #       - meta/llama-3.1-8b-instruct
    #       - meta/llama-3.2-11b-vision-instruct
    #       - meta/llama-3.2-1b-instruct
    #       - meta/llama-3.2-3b-instruct
    #       - meta/llama-3.2-90b-vision-instruct
    #       - meta/llama-3.3-70b-instruct
    #       - meta/llama-4-maverick-17b-128e-instruct
    #       - meta/llama-4-scout-17b-16e-instruct
    #       - meta/llama2-70b
    #       - meta/llama3-70b-instruct
    #       - meta/llama3-8b-instruct
    #       - microsoft/kosmos-2
    #       - microsoft/phi-3-medium-128k-instruct
    #       - microsoft/phi-3-medium-4k-instruct
    #       - microsoft/phi-3-mini-128k-instruct
    #       - microsoft/phi-3-mini-4k-instruct
    #       - microsoft/phi-3-small-128k-instruct
    #       - microsoft/phi-3-small-8k-instruct
    #       - microsoft/phi-3-vision-128k-instruct
    #       - microsoft/phi-3.5-mini-instruct
    #       - microsoft/phi-3.5-moe-instruct
    #       - microsoft/phi-3.5-vision-instruct
    #       - microsoft/phi-4-mini-instruct
    #       - microsoft/phi-4-multimodal-instruct
    #       - mistralai/codestral-22b-instruct-v0.1
    #       - mistralai/mamba-codestral-7b-v0.1
    #       - mistralai/mathstral-7b-v0.1
    #       - mistralai/mistral-7b-instruct-v0.2
    #       - mistralai/mistral-7b-instruct-v0.3
    #       - mistralai/mistral-large
    #       - mistralai/mistral-large-2-instruct
    #       - mistralai/mistral-medium-3-instruct
    #       - mistralai/mistral-small-24b-instruct
    #       - mistralai/mistral-small-3.1-24b-instruct-2503
    #       - mistralai/mixtral-8x22b-instruct-v0.1
    #       - mistralai/mixtral-8x22b-v0.1
    #       - mistralai/mixtral-8x7b-instruct-v0.1
    #       - nv-mistralai/mistral-nemo-12b-instruct
    #       - nvidia/embed-qa-4
    #       - nvidia/llama-3.1-nemoguard-8b-content-safety
    #       - nvidia/llama-3.1-nemoguard-8b-topic-control
    #       - nvidia/llama-3.1-nemotron-51b-instruct
    #       - nvidia/llama-3.1-nemotron-70b-instruct
    #       - nvidia/llama-3.1-nemotron-70b-reward
    #       - nvidia/llama-3.1-nemotron-nano-8b-v1
    #       - nvidia/llama-3.1-nemotron-ultra-253b-v1
    #       - nvidia/llama-3.2-nv-embedqa-1b-v1
    #       - nvidia/llama-3.2-nv-embedqa-1b-v2
    #       - nvidia/llama-3.3-nemotron-super-49b-v1
    #       - nvidia/llama3-chatqa-1.5-70b
    #       - nvidia/llama3-chatqa-1.5-8b
    #       - nvidia/mistral-nemo-minitron-8b-8k-instruct
    #       - nvidia/mistral-nemo-minitron-8b-base
    #       - nvidia/nemoretriever-parse
    #       - nvidia/nemotron-4-340b-instruct
    #       - nvidia/nemotron-4-340b-reward
    #       - nvidia/nemotron-4-mini-hindi-4b-instruct
    #       - nvidia/nemotron-mini-4b-instruct
    #       - nvidia/neva-22b
    #       - nvidia/nv-embed-v1
    #       - nvidia/nv-embedcode-7b-v1
    #       - nvidia/nv-embedqa-e5-v5
    #       - nvidia/nv-embedqa-mistral-7b-v2
    #       - nvidia/nvclip
    #       - nvidia/usdcode-llama-3.1-70b-instruct
    #       - nvidia/vila
    #       - nvquery/meta/llama-3.3-70b-instruct
    #       - qwen/qwen2-7b-instruct
    #       - qwen/qwen2.5-7b-instruct
    #       - qwen/qwen2.5-coder-32b-instruct
    #       - qwen/qwen2.5-coder-7b-instruct
    #       - qwen/qwen3-235b-a22b
    #       - qwen/qwq-32b
    #       - rakuten/rakutenai-7b-chat
    #       - rakuten/rakutenai-7b-instruct
    #       - snowflake/arctic-embed-l
    #       - thudm/chatglm3-6b
    #       - tiiuae/falcon3-7b-instruct
    #       - tokyotech-llm/llama-3-swallow-70b-instruct-v0.1
    #       - upstage/solar-10.7b-instruct
    #       - utter-project/eurollm-9b-instruct
    #       - writer/palmyra-creative-122b
    #       - writer/palmyra-fin-70b-32k
    #       - writer/palmyra-med-70b
    #       - writer/palmyra-med-70b-32k
    #       - yentinglin/llama-3-taiwan-70b-instruct
    #       - zyphra/zamba2-7b-instruct
    #     fetch: false
    #   titleConvo: true
    #   titleModel: "nvidia/nemotron-mini-4b-instruct"
    #   modelDisplayLabel: "Nvidia"

    # # OpenRouter.ai
    # # Model list: https://openrouter.ai/models
    # # Script to fetch models: https://github.com/LibreChat-AI/librechat-config-yaml/blob/main/scripts/openrouter.py
    # - name: "OpenRouter"
    #   apiKey: "user_provided"
    #   baseURL: "https://openrouter.ai/api/v1"
    #   models:
    #     default:
    #       - openrouter/auto
    #       - '---FREE---'
    #       - openrouter/cypher-alpha:free
    #       - agentica-org/deepcoder-14b-preview:free
    #       - arliai/qwq-32b-arliai-rpr-v1:free
    #       - cognitivecomputations/dolphin3.0-mistral-24b:free
    #       - cognitivecomputations/dolphin3.0-r1-mistral-24b:free
    #       - deepseek/deepseek-chat-v3-0324:free
    #       - deepseek/deepseek-chat:free
    #       - deepseek/deepseek-prover-v2:free
    #       - deepseek/deepseek-r1-distill-llama-70b:free
    #       - deepseek/deepseek-r1-distill-qwen-14b:free
    #       - deepseek/deepseek-r1-distill-qwen-32b:free
    #       - deepseek/deepseek-r1-zero:free
    #       - deepseek/deepseek-r1:free
    #       - deepseek/deepseek-v3-base:free
    #       - featherless/qwerky-72b:free
    #       - google/gemini-2.0-flash-exp:free
    #       - google/gemma-2-9b-it:free
    #       - google/gemma-3-12b-it:free
    #       - google/gemma-3-1b-it:free
    #       - google/gemma-3-27b-it:free
    #       - google/gemma-3-4b-it:free
    #       - google/gemma-3n-e4b-it:free
    #       - meta-llama/llama-3.1-405b:free
    #       - meta-llama/llama-3.1-8b-instruct:free
    #       - meta-llama/llama-3.2-11b-vision-instruct:free
    #       - meta-llama/llama-3.2-1b-instruct:free
    #       - meta-llama/llama-3.2-3b-instruct:free
    #       - meta-llama/llama-3.3-70b-instruct:free
    #       - meta-llama/llama-3.3-8b-instruct:free
    #       - meta-llama/llama-4-maverick:free
    #       - meta-llama/llama-4-scout:free
    #       - microsoft/mai-ds-r1:free
    #       - microsoft/phi-4-reasoning-plus:free
    #       - microsoft/phi-4-reasoning:free
    #       - mistralai/devstral-small:free
    #       - mistralai/mistral-7b-instruct:free
    #       - mistralai/mistral-nemo:free
    #       - mistralai/mistral-small-24b-instruct-2501:free
    #       - mistralai/mistral-small-3.1-24b-instruct:free
    #       - moonshotai/kimi-vl-a3b-thinking:free
    #       - moonshotai/moonlight-16b-a3b-instruct:free
    #       - nousresearch/deephermes-3-llama-3-8b-preview:free
    #       - nousresearch/deephermes-3-mistral-24b-preview:free
    #       - nvidia/llama-3.1-nemotron-ultra-253b-v1:free
    #       - nvidia/llama-3.3-nemotron-super-49b-v1:free
    #       - open-r1/olympiccoder-32b:free
    #       - opengvlab/internvl3-14b:free
    #       - opengvlab/internvl3-2b:free
    #       - qwen/qwen-2.5-72b-instruct:free
    #       - qwen/qwen-2.5-7b-instruct:free
    #       - qwen/qwen-2.5-coder-32b-instruct:free
    #       - qwen/qwen-2.5-vl-7b-instruct:free
    #       - qwen/qwen2.5-vl-32b-instruct:free
    #       - qwen/qwen2.5-vl-3b-instruct:free
    #       - qwen/qwen2.5-vl-72b-instruct:free
    #       - qwen/qwen3-14b:free
    #       - qwen/qwen3-235b-a22b:free
    #       - qwen/qwen3-30b-a3b:free
    #       - qwen/qwen3-32b:free
    #       - qwen/qwen3-4b:free
    #       - qwen/qwen3-8b:free
    #       - qwen/qwq-32b:free
    #       - rekaai/reka-flash-3:free
    #       - shisa-ai/shisa-v2-llama3.3-70b:free
    #       - thudm/glm-4-32b:free
    #       - thudm/glm-4-9b:free
    #       - thudm/glm-z1-32b:free
    #       - thudm/glm-z1-9b:free
    #       - tngtech/deepseek-r1t-chimera:free
    #       - '---BETA---'
    #       - anthropic/claude-2.0:beta
    #       - anthropic/claude-2.1:beta
    #       - anthropic/claude-2:beta
    #       - anthropic/claude-3-haiku:beta
    #       - anthropic/claude-3-opus:beta
    #       - anthropic/claude-3-sonnet:beta
    #       - anthropic/claude-3.5-haiku-20241022:beta
    #       - anthropic/claude-3.5-haiku:beta
    #       - anthropic/claude-3.5-sonnet-20240620:beta
    #       - anthropic/claude-3.5-sonnet:beta
    #       - anthropic/claude-3.7-sonnet:beta
    #       - '---EXTENDED---'
    #       - neversleep/llama-3-lumimaid-8b:extended
    #       - openai/gpt-4o:extended
    #       - '---AION-LABS---'
    #       - aion-labs/aion-1.0
    #       - aion-labs/aion-1.0-mini
    #       - aion-labs/aion-rp-llama-3.1-8b
    #       - '---AMAZON---'
    #       - amazon/nova-lite-v1
    #       - amazon/nova-micro-v1
    #       - amazon/nova-pro-v1
    #       - '---ANTHROPIC---'
    #       - anthropic/claude-2
    #       - anthropic/claude-2.0
    #       - anthropic/claude-2.1
    #       - anthropic/claude-3-haiku
    #       - anthropic/claude-3-opus
    #       - anthropic/claude-3-sonnet
    #       - anthropic/claude-3.5-haiku
    #       - anthropic/claude-3.5-haiku-20241022
    #       - anthropic/claude-3.5-sonnet
    #       - anthropic/claude-3.5-sonnet-20240620
    #       - anthropic/claude-3.7-sonnet
    #       - anthropic/claude-3.7-sonnet:thinking
    #       - anthropic/claude-opus-4
    #       - anthropic/claude-sonnet-4
    #       - '---ARCEE-AI---'
    #       - arcee-ai/arcee-blitz
    #       - arcee-ai/caller-large
    #       - arcee-ai/coder-large
    #       - arcee-ai/maestro-reasoning
    #       - arcee-ai/spotlight
    #       - arcee-ai/virtuoso-large
    #       - arcee-ai/virtuoso-medium-v2
    #       - '---COHERE---'
    #       - cohere/command
    #       - cohere/command-a
    #       - cohere/command-r
    #       - cohere/command-r-03-2024
    #       - cohere/command-r-08-2024
    #       - cohere/command-r-plus
    #       - cohere/command-r-plus-04-2024
    #       - cohere/command-r-plus-08-2024
    #       - cohere/command-r7b-12-2024
    #       - '---DEEPSEEK---'
    #       - deepseek/deepseek-chat
    #       - deepseek/deepseek-chat-v3-0324
    #       - deepseek/deepseek-coder
    #       - deepseek/deepseek-prover-v2
    #       - deepseek/deepseek-r1
    #       - deepseek/deepseek-r1-distill-llama-70b
    #       - deepseek/deepseek-r1-distill-llama-8b
    #       - deepseek/deepseek-r1-distill-qwen-1.5b
    #       - deepseek/deepseek-r1-distill-qwen-14b
    #       - deepseek/deepseek-r1-distill-qwen-32b
    #       - '---EVA-UNIT-01---'
    #       - eva-unit-01/eva-llama-3.33-70b
    #       - eva-unit-01/eva-qwen-2.5-32b
    #       - eva-unit-01/eva-qwen-2.5-72b
    #       - '---GOOGLE---'
    #       - google/gemini-2.0-flash-001
    #       - google/gemini-2.0-flash-lite-001
    #       - google/gemini-2.5-flash-preview
    #       - google/gemini-2.5-flash-preview-05-20
    #       - google/gemini-2.5-flash-preview-05-20:thinking
    #       - google/gemini-2.5-flash-preview:thinking
    #       - google/gemini-2.5-pro-exp-03-25
    #       - google/gemini-2.5-pro-preview
    #       - google/gemini-flash-1.5
    #       - google/gemini-flash-1.5-8b
    #       - google/gemini-pro-1.5
    #       - google/gemma-2-27b-it
    #       - google/gemma-2-9b-it
    #       - google/gemma-3-12b-it
    #       - google/gemma-3-27b-it
    #       - google/gemma-3-4b-it
    #       - '---LIQUID---'
    #       - liquid/lfm-3b
    #       - liquid/lfm-40b
    #       - liquid/lfm-7b
    #       - '---META-LLAMA---'
    #       - meta-llama/llama-2-70b-chat
    #       - meta-llama/llama-3-70b-instruct
    #       - meta-llama/llama-3-8b-instruct
    #       - meta-llama/llama-3.1-405b
    #       - meta-llama/llama-3.1-405b-instruct
    #       - meta-llama/llama-3.1-70b-instruct
    #       - meta-llama/llama-3.1-8b-instruct
    #       - meta-llama/llama-3.2-11b-vision-instruct
    #       - meta-llama/llama-3.2-1b-instruct
    #       - meta-llama/llama-3.2-3b-instruct
    #       - meta-llama/llama-3.2-90b-vision-instruct
    #       - meta-llama/llama-3.3-70b-instruct
    #       - meta-llama/llama-4-maverick
    #       - meta-llama/llama-4-scout
    #       - meta-llama/llama-guard-2-8b
    #       - meta-llama/llama-guard-3-8b
    #       - meta-llama/llama-guard-4-12b
    #       - '---MICROSOFT---'
    #       - microsoft/phi-3-medium-128k-instruct
    #       - microsoft/phi-3-mini-128k-instruct
    #       - microsoft/phi-3.5-mini-128k-instruct
    #       - microsoft/phi-4
    #       - microsoft/phi-4-multimodal-instruct
    #       - microsoft/phi-4-reasoning-plus
    #       - microsoft/wizardlm-2-8x22b
    #       - '---MISTRALAI---'
    #       - mistralai/codestral-2501
    #       - mistralai/codestral-mamba
    #       - mistralai/devstral-small
    #       - mistralai/ministral-3b
    #       - mistralai/ministral-8b
    #       - mistralai/mistral-7b-instruct
    #       - mistralai/mistral-7b-instruct-v0.1
    #       - mistralai/mistral-7b-instruct-v0.2
    #       - mistralai/mistral-7b-instruct-v0.3
    #       - mistralai/mistral-large
    #       - mistralai/mistral-large-2407
    #       - mistralai/mistral-large-2411
    #       - mistralai/mistral-medium
    #       - mistralai/mistral-medium-3
    #       - mistralai/mistral-nemo
    #       - mistralai/mistral-saba
    #       - mistralai/mistral-small
    #       - mistralai/mistral-small-24b-instruct-2501
    #       - mistralai/mistral-small-3.1-24b-instruct
    #       - mistralai/mistral-tiny
    #       - mistralai/mixtral-8x22b-instruct
    #       - mistralai/mixtral-8x7b-instruct
    #       - mistralai/pixtral-12b
    #       - mistralai/pixtral-large-2411
    #       - '---NEVERSLEEP---'
    #       - neversleep/llama-3-lumimaid-70b
    #       - neversleep/llama-3-lumimaid-8b
    #       - neversleep/llama-3.1-lumimaid-70b
    #       - neversleep/llama-3.1-lumimaid-8b
    #       - neversleep/noromaid-20b
    #       - '---NOUSRESEARCH---'
    #       - nousresearch/hermes-2-pro-llama-3-8b
    #       - nousresearch/hermes-3-llama-3.1-405b
    #       - nousresearch/hermes-3-llama-3.1-70b
    #       - nousresearch/nous-hermes-2-mixtral-8x7b-dpo
    #       - '---OPENAI---'
    #       - openai/chatgpt-4o-latest
    #       - openai/codex-mini
    #       - openai/gpt-3.5-turbo
    #       - openai/gpt-3.5-turbo-0125
    #       - openai/gpt-3.5-turbo-0613
    #       - openai/gpt-3.5-turbo-1106
    #       - openai/gpt-3.5-turbo-16k
    #       - openai/gpt-3.5-turbo-instruct
    #       - openai/gpt-4
    #       - openai/gpt-4-0314
    #       - openai/gpt-4-1106-preview
    #       - openai/gpt-4-32k
    #       - openai/gpt-4-32k-0314
    #       - openai/gpt-4-turbo
    #       - openai/gpt-4-turbo-preview
    #       - openai/gpt-4.1
    #       - openai/gpt-4.1-mini
    #       - openai/gpt-4.1-nano
    #       - openai/gpt-4.5-preview
    #       - openai/gpt-4o
    #       - openai/gpt-4o-2024-05-13
    #       - openai/gpt-4o-2024-08-06
    #       - openai/gpt-4o-2024-11-20
    #       - openai/gpt-4o-mini
    #       - openai/gpt-4o-mini-2024-07-18
    #       - openai/gpt-4o-mini-search-preview
    #       - openai/gpt-4o-search-preview
    #       - openai/o1
    #       - openai/o1-mini
    #       - openai/o1-mini-2024-09-12
    #       - openai/o1-preview
    #       - openai/o1-preview-2024-09-12
    #       - openai/o1-pro
    #       - openai/o3
    #       - openai/o3-mini
    #       - openai/o3-mini-high
    #       - openai/o4-mini
    #       - openai/o4-mini-high
    #       - '---PERPLEXITY---'
    #       - perplexity/llama-3.1-sonar-large-128k-online
    #       - perplexity/llama-3.1-sonar-small-128k-online
    #       - perplexity/r1-1776
    #       - perplexity/sonar
    #       - perplexity/sonar-deep-research
    #       - perplexity/sonar-pro
    #       - perplexity/sonar-reasoning
    #       - perplexity/sonar-reasoning-pro
    #       - '---QWEN---'
    #       - qwen/qwen-2-72b-instruct
    #       - qwen/qwen-2.5-72b-instruct
    #       - qwen/qwen-2.5-7b-instruct
    #       - qwen/qwen-2.5-coder-32b-instruct
    #       - qwen/qwen-2.5-vl-7b-instruct
    #       - qwen/qwen-max
    #       - qwen/qwen-plus
    #       - qwen/qwen-turbo
    #       - qwen/qwen-vl-max
    #       - qwen/qwen-vl-plus
    #       - qwen/qwen2.5-coder-7b-instruct
    #       - qwen/qwen2.5-vl-32b-instruct
    #       - qwen/qwen2.5-vl-72b-instruct
    #       - qwen/qwen3-14b
    #       - qwen/qwen3-235b-a22b
    #       - qwen/qwen3-30b-a3b
    #       - qwen/qwen3-32b
    #       - qwen/qwen3-8b
    #       - qwen/qwq-32b
    #       - qwen/qwq-32b-preview
    #       - '---SAO10K---'
    #       - sao10k/fimbulvetr-11b-v2
    #       - sao10k/l3-euryale-70b
    #       - sao10k/l3-lunaris-8b
    #       - sao10k/l3.1-euryale-70b
    #       - sao10k/l3.3-euryale-70b
    #       - '---THEDRUMMER---'
    #       - thedrummer/anubis-pro-105b-v1
    #       - thedrummer/rocinante-12b
    #       - thedrummer/skyfall-36b-v2
    #       - thedrummer/unslopnemo-12b
    #       - '---THUDM---'
    #       - thudm/glm-4-32b
    #       - thudm/glm-z1-32b
    #       - thudm/glm-z1-rumination-32b
    #       - '---X-AI---'
    #       - x-ai/grok-2-1212
    #       - x-ai/grok-2-vision-1212
    #       - x-ai/grok-3-beta
    #       - x-ai/grok-3-mini-beta
    #       - x-ai/grok-beta
    #       - x-ai/grok-vision-beta
    #       - '---OTHERS---'
    #       - 01-ai/yi-large
    #       - aetherwiing/mn-starcannon-12b
    #       - ai21/jamba-1.6-large
    #       - ai21/jamba-1.6-mini
    #       - alfredpros/codellama-7b-instruct-solidity
    #       - all-hands/openhands-lm-32b-v0.1
    #       - allenai/olmo-7b-instruct
    #       - alpindale/goliath-120b
    #       - alpindale/magnum-72b
    #       - anthracite-org/magnum-v2-72b
    #       - anthracite-org/magnum-v4-72b
    #       - cognitivecomputations/dolphin-mixtral-8x22b
    #       - eleutherai/llemma_7b
    #       - gryphe/mythomax-l2-13b
    #       - inception/mercury-coder-small-beta
    #       - infermatic/mn-inferor-12b
    #       - inflection/inflection-3-pi
    #       - inflection/inflection-3-productivity
    #       - mancer/weaver
    #       - minimax/minimax-01
    #       - nothingiisreal/mn-celeste-12b
    #       - nvidia/llama-3.1-nemotron-70b-instruct
    #       - nvidia/llama-3.3-nemotron-super-49b-v1
    #       - pygmalionai/mythalion-13b
    #       - raifle/sorcererlm-8x22b
    #       - scb10x/llama3.1-typhoon2-70b-instruct
    #       - scb10x/llama3.1-typhoon2-8b-instruct
    #       - sophosympatheia/midnight-rose-70b
    #       - undi95/remm-slerp-l2-13b
    #       - undi95/toppy-m-7b
    #     fetch: false
    #   dropParams:
    #     - "stop"
    #   titleConvo: true
    #   titleModel: "openai/gpt-4o-mini"
    #   summarize: false
    #   summaryModel: "openai/gpt-4o-mini"
    #   forcePrompt: false
    #   modelDisplayLabel: "OpenRouter"

    # # Preplexity
    # # Model list: https://docs.perplexity.ai/docs/model-cards
    # - name: "Perplexity"
    #   apiKey: "user_provided"
    #   baseURL: "https://api.perplexity.ai/"
    #   models:
    #     default:
    #       - r1-1776
    #       - sonar
    #       - sonar-deep-research
    #       - sonar-pro
    #       - sonar-reasoning
    #       - sonar-reasoning-pro
    #     fetch: false # fetching list of models is not supported
    #   titleConvo: true
    #   titleModel: "current_model"
    #   summarize: false
    #   summaryModel: "sonar"
    #   forcePrompt: false
    #   dropParams:
    #     - "stop"
    #     - "frequency_penalty"
    #   modelDisplayLabel: "Perplexity"

    # # SambaNova
    # # https://cloud.sambanova.ai/apis
    # - name: "SambaNova"
    #   iconURL: "https://sambanova.ai/hubfs/logotype_sambanova_orange.png"
    #   apiKey: "user_provided"
    #   baseURL: "https://api.sambanova.ai/v1/"
    #   models:
    #     default:
    #       - DeepSeek-R1
    #       - DeepSeek-R1-Distill-Llama-70B
    #       - Llama-3.1-Tulu-3-405B
    #       - Llama-3.2-11B-Vision-Instruct
    #       - Llama-3.2-90B-Vision-Instruct
    #       - Meta-Llama-3.1-405B-Instruct
    #       - Meta-Llama-3.1-70B-Instruct
    #       - Meta-Llama-3.1-8B-Instruct
    #       - Meta-Llama-3.2-1B-Instruct
    #       - Meta-Llama-3.2-3B-Instruct
    #       - Meta-Llama-3.3-70B-Instruct
    #       - Meta-Llama-Guard-3-8B
    #       - QwQ-32B-Preview
    #       - Qwen2-Audio-7B-Instruct
    #       - Qwen2.5-72B-Instruct
    #       - Qwen2.5-Coder-32B-Instruct
    #     fetch: false
    #   titleConvo: true
    #   titleModel: "Meta-Llama-3.1-8B-Instruct"
    #   modelDisplayLabel: "SambaNova"

    # # together.ai
    # # https://api.together.ai/settings/api-keys
    # # Model list: https://docs.together.ai/docs/inference-models
    # - name: "together.ai"
    #   apiKey: "user_provided"
    #   baseURL: "https://api.together.xyz"
    #   models:
    #     default:
    #       - Gryphe/MythoMax-L2-13b
    #       - Gryphe/MythoMax-L2-13b-Lite
    #       - NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO
    #       - Qwen/QwQ-32B
    #       - Qwen/Qwen2-72B-Instruct
    #       - Qwen/Qwen2-VL-72B-Instruct
    #       - Qwen/Qwen2.5-72B-Instruct-Turbo
    #       - Qwen/Qwen2.5-7B-Instruct-Turbo
    #       - Qwen/Qwen2.5-Coder-32B-Instruct
    #       - Qwen/Qwen2.5-VL-72B-Instruct
    #       - Qwen/Qwen3-235B-A22B-fp8
    #       - Qwen/Qwen3-235B-A22B-fp8-tput
    #       - arcee-ai/arcee-blitz
    #       - arcee-ai/caller
    #       - arcee-ai/coder-large
    #       - arcee-ai/maestro-reasoning
    #       - arcee-ai/virtuoso-large
    #       - arcee-ai/virtuoso-medium-v2
    #       - arcee_ai/arcee-spotlight
    #       - deepseek-ai/DeepSeek-R1
    #       - deepseek-ai/DeepSeek-R1-Distill-Llama-70B
    #       - deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free
    #       - deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
    #       - deepseek-ai/DeepSeek-R1-Distill-Qwen-14B
    #       - deepseek-ai/DeepSeek-V3
    #       - deepseek-ai/DeepSeek-V3-p-dp
    #       - google/gemma-2-27b-it
    #       - google/gemma-2b-it
    #       - marin-community/marin-8b-instruct
    #       - meta-llama/Llama-3-70b-chat-hf
    #       - meta-llama/Llama-3-8b-chat-hf
    #       - meta-llama/Llama-3.2-11B-Vision-Instruct-Turbo
    #       - meta-llama/Llama-3.2-3B-Instruct-Turbo
    #       - meta-llama/Llama-3.2-90B-Vision-Instruct-Turbo
    #       - meta-llama/Llama-3.3-70B-Instruct-Turbo
    #       - meta-llama/Llama-3.3-70B-Instruct-Turbo-Free
    #       - meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8
    #       - meta-llama/Llama-4-Scout-17B-16E-Instruct
    #       - meta-llama/Llama-Vision-Free
    #       - meta-llama/Meta-Llama-3-70B-Instruct-Turbo
    #       - meta-llama/Meta-Llama-3-8B-Instruct-Lite
    #       - meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo
    #       - meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo
    #       - meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo
    #       - mistralai/Mistral-7B-Instruct-v0.1
    #       - mistralai/Mistral-7B-Instruct-v0.2
    #       - mistralai/Mistral-7B-Instruct-v0.3
    #       - mistralai/Mistral-Small-24B-Instruct-2501
    #       - mistralai/Mixtral-8x7B-Instruct-v0.1
    #       - nvidia/Llama-3.1-Nemotron-70B-Instruct-HF
    #       - perplexity-ai/r1-1776
    #       - scb10x/scb10x-llama3-1-typhoon2-70b-instruct
    #       - scb10x/scb10x-llama3-1-typhoon2-8b-instruct
    #       - togethercomputer/MoA-1
    #       - togethercomputer/MoA-1-Turbo
    #       - togethercomputer/Refuel-Llm-V2
    #       - togethercomputer/Refuel-Llm-V2-Small
    #     fetch: false
    #   titleConvo: true
    #   titleModel: "openchat/openchat-3.5-1210"
    #   summarize: false
    #   summaryModel: "openchat/openchat-3.5-1210"
    #   forcePrompt: false
    #   modelDisplayLabel: "together.ai"

    # # Unify
    # # Model list: https://unify.ai/chat
    # - name: "Unify"
    #   apiKey: "user_provided"
    #   baseURL: "https://api.unify.ai/v0/"
    #   models:
    #     default:
    #       - chatgpt-4o-latest@openai
    #       - claude-3-haiku@anthropic
    #       - claude-3-haiku@aws-bedrock
    #       - claude-3-haiku@vertex-ai
    #       - claude-3-opus@anthropic
    #       - claude-3-opus@aws-bedrock
    #       - claude-3-opus@vertex-ai
    #       - claude-3-sonnet@anthropic
    #       - claude-3-sonnet@aws-bedrock
    #       - claude-3.5-haiku@anthropic
    #       - claude-3.5-haiku@aws-bedrock
    #       - claude-3.5-haiku@replicate
    #       - claude-3.5-haiku@vertex-ai
    #       - claude-3.5-sonnet-20240620@anthropic
    #       - claude-3.5-sonnet-20240620@aws-bedrock
    #       - claude-3.5-sonnet-20240620@vertex-ai
    #       - claude-3.5-sonnet@anthropic
    #       - claude-3.5-sonnet@aws-bedrock
    #       - claude-3.5-sonnet@replicate
    #       - claude-3.5-sonnet@vertex-ai
    #       - claude-3.7-sonnet@anthropic
    #       - claude-3.7-sonnet@aws-bedrock
    #       - claude-3.7-sonnet@replicate
    #       - claude-3.7-sonnet@vertex-ai
    #       - command-r-plus@aws-bedrock
    #       - deepseek-r1@aws-bedrock
    #       - deepseek-r1@deepinfra
    #       - deepseek-r1@deepseek
    #       - deepseek-r1@fireworks-ai
    #       - deepseek-r1@replicate
    #       - deepseek-r1@together-ai
    #       - deepseek-v3-0324@deepinfra
    #       - deepseek-v3-0324@fireworks-ai
    #       - deepseek-v3@deepinfra
    #       - deepseek-v3@deepseek
    #       - deepseek-v3@fireworks-ai
    #       - deepseek-v3@replicate
    #       - deepseek-v3@together-ai
    #       - gemini-1.5-flash-002@vertex-ai
    #       - gemini-1.5-flash@vertex-ai
    #       - gemini-1.5-pro-002@vertex-ai
    #       - gemini-1.5-pro@vertex-ai
    #       - gemini-2.0-flash-lite@vertex-ai
    #       - gemini-2.0-flash@vertex-ai
    #       - gemini-2.5-flash@vertex-ai
    #       - gemini-2.5-pro@vertex-ai
    #       - gemma-2-27b-it@together-ai
    #       - gemma-2-9b-it@groq
    #       - gemma-3-12b-it@deepinfra
    #       - gemma-3-27b-it@deepinfra
    #       - gemma-3-4b-it@deepinfra
    #       - gpt-3.5-turbo@openai
    #       - gpt-4-turbo@openai
    #       - gpt-4.1-mini@openai
    #       - gpt-4.1-nano@openai
    #       - gpt-4.1@openai
    #       - gpt-4.5-preview@openai
    #       - gpt-4@openai
    #       - gpt-4o-2024-05-13@openai
    #       - gpt-4o-2024-08-06@openai
    #       - gpt-4o-2024-11-20@openai
    #       - gpt-4o-mini-search-preview@openai
    #       - gpt-4o-mini@openai
    #       - gpt-4o-search-preview@openai
    #       - gpt-4o@openai
    #       - grok-2-vision@xai
    #       - grok-2@xai
    #       - grok-3-fast@xai
    #       - grok-3-mini-fast@xai
    #       - grok-3-mini@xai
    #       - grok-3@xai
    #       - llama-3-70b-chat@aws-bedrock
    #       - llama-3-70b-chat@deepinfra
    #       - llama-3-70b-chat@groq
    #       - llama-3-70b-chat@replicate
    #       - llama-3-8b-chat@aws-bedrock
    #       - llama-3-8b-chat@deepinfra
    #       - llama-3-8b-chat@groq
    #       - llama-3-8b-chat@replicate
    #       - llama-3.1-405b-chat@aws-bedrock
    #       - llama-3.1-405b-chat@deepinfra
    #       - llama-3.1-405b-chat@fireworks-ai
    #       - llama-3.1-405b-chat@replicate
    #       - llama-3.1-405b-chat@together-ai
    #       - llama-3.1-405b-chat@vertex-ai
    #       - llama-3.1-70b-chat@aws-bedrock
    #       - llama-3.1-70b-chat@deepinfra
    #       - llama-3.1-70b-chat@fireworks-ai
    #       - llama-3.1-70b-chat@together-ai
    #       - llama-3.1-70b-chat@vertex-ai
    #       - llama-3.1-8b-chat@aws-bedrock
    #       - llama-3.1-8b-chat@deepinfra
    #       - llama-3.1-8b-chat@fireworks-ai
    #       - llama-3.1-8b-chat@groq
    #       - llama-3.1-8b-chat@together-ai
    #       - llama-3.1-8b-chat@vertex-ai
    #       - llama-3.1-nemotron-70b-chat@deepinfra
    #       - llama-3.2-11b-chat@deepinfra
    #       - llama-3.2-11b-chat@together-ai
    #       - llama-3.2-11b-chat@vertex-ai
    #       - llama-3.2-1b-chat@aws-bedrock
    #       - llama-3.2-1b-chat@deepinfra
    #       - llama-3.2-3b-chat@aws-bedrock
    #       - llama-3.2-3b-chat@deepinfra
    #       - llama-3.2-3b-chat@together-ai
    #       - llama-3.2-90b-chat@deepinfra
    #       - llama-3.2-90b-chat@together-ai
    #       - llama-3.2-90b-chat@vertex-ai
    #       - llama-3.3-70b-chat@aws-bedrock
    #       - llama-3.3-70b-chat@deepinfra
    #       - llama-3.3-70b-chat@fireworks-ai
    #       - llama-3.3-70b-chat@groq
    #       - llama-3.3-70b-chat@together-ai
    #       - llama-3.3-70b-chat@vertex-ai
    #       - llama-4-maverick-instruct@deepinfra
    #       - llama-4-maverick-instruct@fireworks-ai
    #       - llama-4-maverick-instruct@groq
    #       - llama-4-maverick-instruct@replicate
    #       - llama-4-maverick-instruct@together-ai
    #       - llama-4-maverick-instruct@vertex-ai
    #       - llama-4-scout-instruct@deepinfra
    #       - llama-4-scout-instruct@fireworks-ai
    #       - llama-4-scout-instruct@groq
    #       - llama-4-scout-instruct@replicate
    #       - llama-4-scout-instruct@together-ai
    #       - llama-4-scout-instruct@vertex-ai
    #       - ministral-3b@mistral-ai
    #       - ministral-8b@mistral-ai
    #       - mistral-7b-instruct-v0.3@deepinfra
    #       - mistral-7b-instruct-v0.3@together-ai
    #       - mistral-large@mistral-ai
    #       - mistral-large@vertex-ai
    #       - mistral-nemo@deepinfra
    #       - mistral-nemo@mistral-ai
    #       - mistral-nemo@vertex-ai
    #       - mistral-small@deepinfra
    #       - mistral-small@mistral-ai
    #       - mistral-small@together-ai
    #       - mistral-small@vertex-ai
    #       - mixtral-8x22b-instruct-v0.1@fireworks-ai
    #       - mixtral-8x7b-instruct-v0.1@deepinfra
    #       - o1-mini@openai
    #       - o1-pro@openai
    #       - o1@openai
    #       - o3-mini@openai
    #       - o3@openai
    #       - o4-mini@openai
    #       - qwen-2-72b-instruct@together-ai
    #       - qwen-2.5-72b-instruct@deepinfra
    #       - qwen-2.5-72b-instruct@fireworks-ai
    #       - qwen-2.5-72b-instruct@together-ai
    #       - qwen-2.5-7b-instruct@deepinfra
    #       - qwen-2.5-7b-instruct@together-ai
    #       - qwen-2.5-coder-32b-instruct@deepinfra
    #       - qwen-2.5-coder-32b-instruct@together-ai
    #       - qwen-3-235b-a22b-instruct@deepinfra
    #       - qwen-3-235b-a22b-instruct@fireworks-ai
    #       - qwen-3-235b-a22b-instruct@together-ai
    #       - qwen-3-30b-a3b-instruct@deepinfra
    #       - qwen-3-30b-a3b-instruct@fireworks-ai
    #       - qwen-qwq-32b@deepinfra
    #       - qwen-qwq-32b@fireworks-ai
    #       - qwen-qwq-32b@groq
    #       - qwen-qwq-32b@together-ai
    #     fetch: false
    #   titleConvo: true
    #   titleModel: "gpt-4o-mini@openai"
    #   dropParams:
    #     - "stop"
    #     - "user"
    #     - "frequency_penalty"
    #     - "presence_penalty"

    # # xAI
    # # https://x.ai/api
    # - name: "xai"
    #   apiKey: "user_provided"
    #   baseURL: "https://api.x.ai/v1"
    #   models:
    #     default:
    #       - grok-2-1212
    #       - grok-2-vision-1212
    #       - grok-3-beta
    #       - grok-3-mini-beta
    #       - grok-beta
    #       - grok-vision-beta
    #     fetch: false
    #   titleConvo: true
    #   titleMethod: "completion"
    #   titleModel: "grok-beta"
    #   summarize: false
    #   summaryModel: "grok-beta"
    #   forcePrompt: false
    #   modelDisplayLabel: "Grok"