# For more information, see the Configuration Guide:
# https://www.librechat.ai/docs/configuration/librechat_yaml

# Configuration version (required)
version: 1.2.1

# Cache settings: Set to true to enable caching
cache: true

# File storage configuration
# Single strategy for all file types (legacy format, still supported)
# fileStrategy: "s3"

# Granular file storage strategies (new format - recommended)
# Allows different storage strategies for different file types
# fileStrategy:
#   avatar: "s3"        # Storage for user/agent avatar images
#   image: "firebase"   # Storage for uploaded images in chats
#   document: "local"   # Storage for document uploads (PDFs, text files, etc.)

# Available strategies: "local", "s3", "firebase"
# If not specified, defaults to "local" for all file types
# You can mix and match strategies based on your needs:
# - Use S3 for avatars for fast global access
# - Use Firebase for images with automatic optimization
# - Use local storage for documents for privacy/compliance

# Custom interface configuration
interface:
  customWelcome: 'ИИ-агенты работают для Вас!'
  # Enable/disable file search as a chatarea selection (default: true)
  # Note: This setting does not disable the Agents File Search Capability.
  # To disable the Agents Capability, see the Agents Endpoint configuration instead.
  fileSearch: true
  # Privacy policy settings
  privacyPolicy:
    externalUrl: 'https://agentsworks.ru/privacy-policy'
    openNewTab: true

  # Terms of service
  termsOfService:
    externalUrl: 'https://agentsworks.ru/tos'
    openNewTab: true
    modalAcceptance: true
    modalTitle: 'Пользовательское соглашение AgentsWorks'
    modalContent: |
      # Пользовательское соглашение AgentsWorks

      Дата последнего обновления: [12.01.2026]

      1. Принятие соглашения
      Путем регистрации, доступа или использования платформы AgentsWorks («Платформа», «Сервис», «Мы») вы («Пользователь», «Вы») подтверждаете, что прочитали, поняли и безоговорочно соглашаетесь соблюдать настоящее Пользовательское соглашение («Соглашение»), 
      а также Политику конфиденциальности и Правила использования контента. Если вы не согласны с условиями, вы не имеете права использовать Платформу.
      
      2. Определения
      
      Платформа AgentsWorks: Онлайн-платформа и веб-сайт, предоставляющие инструменты для создания, тестирования, публикации, распространения и использования ИИ-агентов.
      
      ИИ-агент (Бот): Программный объект, созданный с помощью инструментов Платформы, способный выполнять задачи, взаимодействовать с пользователями, генерировать контент и т.д., на основе заложенных моделей, данных и инструкций.
      
      Создатель: Пользователь, который создает, обучает, настраивает и публикует ИИ-агента на Платформе.
      
      Пользователь агента: Лицо, которое взаимодействует с ИИ-агентами, опубликованными на Платформе.
      
      Публичный агент: ИИ-агент, размещенный Создателем в общем каталоге Платформы для свободного или платного доступа другим пользователям.
      
      Контент: Любые тексты, код, изображения, данные, инструкции (промпты), конфигурации, имена, описания, а также выходные данные (output), генерируемые ИИ-агентами.
      
      3. Условия использования
      3.1. Для использования Платформы вам должно быть не менее 14 лет. Вы подтверждаете свою дееспособность.
      3.2. Вы обязуетесь предоставлять достоверную информацию при регистрации и поддерживать её в актуальном состоянии.
      3.3. Вы несете ответственность за сохранность своих учетных данных и за все действия, совершенные под вашей учетной записью.
      
      4. Создание и публикация ИИ-агентов
      4.1. Ответственность Создателя: Вы, как Создатель, полностью несете ответственность за контент, поведение, функционал и выходные данные вашего ИИ-агента, включая данные, использованные для его обучения/настройки (fine-tuning).
      4.2. Гарантии: Вы гарантируете, что:
      * Ваш агент и связанный с ним контент не нарушают права третьих лиц (авторские права, товарные знаки, права на публичность, коммерческую тайну).
      * Ваш агент не предназначен для совершения мошеннических, вредоносных или незаконных действий.
      * Ваш агент не генерирует и не распространяет контент, который является незаконным, дискриминационным, клеветническим, порнографическим, призывающим к насилию, или представляет собой спам.
      * Вы четко информируете пользователей о том, что они взаимодействуют с ИИ, а не с человеком, где это необходимо.
      4.3. Модерация: Мы оставляем за собой право, но не обязаны, проверять, модерировать, блокировать или удалять любых ИИ-агентов или генерируемый ими контент, которые, по нашему мнению, нарушают настоящее Соглашение. Решения модерации являются окончательными.
      4.4. Лицензия Платформе: Размещая Публичного агента на Платформе, вы предоставляете AgentsWorks неисключительную, безвозмездную, мировую лицензию на его размещение, хранение, техническое воспроизведение и демонстрацию в целях функционирования Платформы.
      
      5. Использование ИИ-агентов
      5.1. Вы понимаете, что ИИ-агенты создаются третьими лицами (Создателями), и AgentsWorks не контролирует и не гарантирует точность, надежность, законность или безопасность их выходных данных.
      5.2. Контент, генерируемый ИИ (Output):
      * Он может содержать ошибки, неточности или неподходящие материалы.
      * Он не является профессиональной консультацией (медицинской, юридической, финансовой и т.д.). Вы используете его на свой страх и риск.
      * Вы сохраняете права на контент, сгенерированный для вас агентом, при условии соблюдения условий Соглашения и прав Создателя агента.
      5.3. Запрещено использовать ИИ-агентов для:
      * Обхода систем безопасности или получения несанкционированного доступа.
      * Генерации массового спама или вредоносного ПО.
      * Выдачи себя за другое лицо или организацию.
      * Любой деятельности, нарушающей применимое законодательство.
      
      6. Интеллектуальная собственность
      6.1. AgentsWorks сохраняет за собой все права, титулы и интересы в отношении самой Платформы, её исходного кода, дизайна, функционала и товарных знаков.
      6.2. Создатель сохраняет права интеллектуальной собственности на своего ИИ-агента (его уникальную конфигурацию, промпты, данные для тонкой настройки), за исключением базовых моделей и инструментов, предоставленных Платформой.
      6.3. Отношения по лицензированию между Создателем и Пользователем агента (например, для платных агентов) регулируются отдельной лицензией или условиями, которые Создатель устанавливает в описании агента. AgentsWorks выступает лишь техническим посредником.
      
      7. Коммерческие условия (если есть монетизация)
      7.1. Платные агенты: Создатель может установить плату за доступ к своему агенту. AgentsWorks может удерживать комиссию с каждой транзакции. Конкретные ставки публикуются на странице с тарифами.
      7.2. Подписки: Доступ к премиум-функциям Платформы может предоставляться по подписке. Условия автоматического продления и отмены описаны в соответствующих разделах.
      7.3. Возвраты: Все платежи за цифровые продукты (доступ к агентам, подписки) являются окончательными. Возвраты рассматриваются в исключительных случаях по усмотрению службы поддержки.
      
      8. Отказ от гарантий и ограничение ответственности
      8.1. ПЛАТФОРМА ПРЕДОСТАВЛЯЕТСЯ «КАК ЕСТЬ» И «ПО ДОСТУПНОСТИ». МЫ НЕ ДАЕМ НИКАКИХ ЯВНЫХ ИЛИ ПОДРАЗУМЕВАЕМЫХ ГАРАНТИЙ, ВКЛЮЧАЯ ГАРАНТИИ ТОВАРНОЙ ПРИГОДНОСТИ, СООТВЕТСТВИЯ КОНКРЕТНОЙ ЦЕЛИ И НЕНАРУШЕНИЯ ПРАВ.
      8.2. AgentsWorks НЕ НЕСЕТ ОТВЕТСТВЕННОСТИ ЗА КОНТЕНТ, ГЕНЕРИРУЕМЫЙ ИИ-АГЕНТАМИ, ЗА ДЕЙСТВИЯ СОЗДАТЕЛЕЙ ИЛИ ПОЛЬЗОВАТЕЛЕЙ, А ТАКЖЕ ЗА ЛЮБЫЕ КОСВЕННЫЕ, СЛУЧАЙНЫЕ, ШТРАФНЫЕ УБЫТКИ ИЛИ УПУЩЕННУЮ ВЫГОДУ.
      
      9. Прекращение действия
      Мы можем приостановить или прекратить ваш доступ к Платформе немедленно, без предварительного уведомления, если вы нарушите настоящее Соглашение.
      
      10. Изменения в соглашении
      Мы оставляем за собой право изменять условия данного Соглашения. О существенных изменениях мы уведомим вас через Платформу или по электронной почте. Продолжение использования Сервиса после внесения изменений означает ваше согласие с ними.
      
      11. Применимое право и разрешение споров
      Все возможные споры, вытекающие из настоящего Пользовательского соглашения или связанные с ним, подлежат разрешению в соответствии с законодательством Российской Федерации.

  endpointsMenu: true
  modelSelect: true
  parameters: true
  sidePanel: true
  presets: true
  prompts:
    use: true
    share: true
    public: false
  bookmarks: true
  multiConvo: true
  agents:
    use: true
    share: true
    public: true
  peoplePicker:
    users: true
    groups: true
    roles: true
  marketplace:
    use: true
  fileCitations: true
  mcpServers:
    # MCP Servers configuration
    # Controls user permissions for MCP (Model Context Protocol) server management
    # - use: Allow users to use configured MCP servers
    # - create: Allow users to create and manage new MCP servers
    # - share: Allow users to share MCP servers with other users
    # - public: Allow users to share MCP servers publicly (with everyone)
    use: true
    share: false
    create: false
    public: false
    # Creation / edit MCP server config Dialog config example
    # trustCheckbox:
    #   label:
    #     en: 'I understand and I want to continue'
    #     de: 'Ich verstehe und möchte fortfahren'
    #     de-DE: 'Ich verstehe und möchte fortfahren' # You can narrow translation to regions like (de-DE or de-CH)
    #   subLabel:
    #     en: |
    #       Librechat hasn't reviewed this MCP server. Attackers may attempt to steal your data or trick the model into taking unintended actions, including destroying data. <a href="https://google.de" target="_blank"><strong>Learn more.</strong></a>
    #     de: |
    #       LibreChat hat diesen MCP-Server nicht überprüft. Angreifer könnten versuchen, Ihre Daten zu stehlen oder das Modell zu unbeabsichtigten Aktionen zu verleiten, einschließlich der Zerstörung von Daten. <a href="https://google.de" target="_blank"><strong>Mehr erfahren.</strong></a>

  # Temporary chat retention period in hours (default: 720, min: 1, max: 8760)
  # temporaryChatRetention: 1

# Example Cloudflare turnstile (optional)
#turnstile:
#  siteKey: "your-site-key-here"
#  options:
#    language: "auto"    # "auto" or an ISO 639-1 language code (e.g. en)
#    size: "normal"      # Options: "normal", "compact", "flexible", or "invisible"

# Example Registration Object Structure (optional)
registration:
  socialLogins: ['github', 'google', 'discord', 'openid', 'facebook', 'apple', 'saml']
  # allowedDomains:
  # - "gmail.com"

# Example Balance settings
balance:
  enabled: false
  startBalance: 20000
  autoRefillEnabled: false
  refillIntervalValue: 1
  refillIntervalUnit: 'days'
  refillAmount: 10000

# Example Transactions settings
# Controls whether to save transaction records to the database
# Default is true (enabled)
#transactions:
#  enabled: false
# Note: If balance.enabled is true, transactions will always be enabled
# regardless of this setting to ensure balance tracking works correctly

# speech:
#   tts:
#     openai:
#       url: ''
#       apiKey: '${TTS_API_KEY}'
#       model: ''
#       voices: ['']

#
#   stt:
#     openai:
#       url: ''
#       apiKey: '${STT_API_KEY}'
#       model: ''

rateLimits:
  fileUploads:
    ipMax: 100
    ipWindowInMinutes: 60  # Rate limit window for file uploads per IP
    userMax: 10
    userWindowInMinutes: 60  # Rate limit window for file uploads per user
#   conversationsImport:
#     ipMax: 100
#     ipWindowInMinutes: 60  # Rate limit window for conversation imports per IP
#     userMax: 50
#     userWindowInMinutes: 60  # Rate limit window for conversation imports per user

# Agent Actions domain restrictions (OpenAPI spec validation)
# SECURITY: If not configured, SSRF targets are blocked (localhost, private IPs, .internal/.local TLDs).
# To allow internal targets, you MUST explicitly add them to allowedDomains.
# Supports wildcards: '*.example.com' and protocol/port restrictions: 'https://api.example.com:8443'
actions:
  allowedDomains:
    - 'swapi.dev'
    - 'librechat.ai'
    - 'google.com'
    # - 'http://10.225.26.25:7894'  # Internal IP with protocol/port (uncomment if needed)

# MCP Server domain restrictions for remote transports (SSE, WebSocket, HTTP)
# SECURITY: If not configured, SSRF targets are blocked (localhost, private IPs, .internal/.local TLDs).
# To allow internal targets like host.docker.internal, you MUST explicitly add them to allowedDomains.
# Supports wildcards: '*.example.com' matches 'api.example.com', 'staging.example.com', etc.
# Supports protocol/port restrictions: 'https://api.example.com:8443' restricts to specific protocol/port.
mcpSettings:
  allowedDomains:
    - 'host.docker.internal'    # Docker host access (required for Docker setups)
    - 'localhost'               # Local development
#     - '*.example.com'           # Wildcard subdomain
#     - 'https://secure.api.com'  # Protocol-restricted
#     - 'http://internal:8080'    # Protocol and port restricted

# Example MCP Servers Object Structure
mcpServers:
  bitrix24:
    type: streamable-http
    url: "http://localhost:8093/mcp"
    headers:
      X-Auth-Token: "{{BITRIX_WEBHOOK_URL}}"
    customUserVars:
      BITRIX_WEBHOOK_URL:
        title: "BITRIX_WEBHOOK_URL"
        description: "Укажите свой BITRIX_WEBHOOK_URL к bitrix24"
  tinkoff:
    type: streamable-http
    url: "http://localhost:8000/mcp"
    headers:
      X-Auth-Token: "{{TINKOFF_INVEST_TOKEN}}"
    customUserVars:
      TINKOFF_INVEST_TOKEN:
        title: "Token Т-Инвестиции"
        description: "Укажите свой токен доступа к Т-Инвестиции"
  web-search:
    type: streamable-http
    url: "http://localhost:8092/mcp"
# mcpServers:
#   everything:
#     # type: sse # type can optionally be omitted
#     url: http://localhost:3001/sse
#     timeout: 60000  # 1 minute timeout for this server, this is the default timeout for MCP servers.
#   puppeteer:
#     type: stdio
#     command: npx
#     args:
#       - -y
#       - "@modelcontextprotocol/server-puppeteer"
#     timeout: 300000  # 5 minutes timeout for this server
#   filesystem:
#     # type: stdio
#     command: npx
#     args:
#       - -y
#       - "@modelcontextprotocol/server-filesystem"
#       - /home/user/LibreChat/
#     iconPath: /home/user/LibreChat/client/public/assets/logo.svg
#   mcp-obsidian:
#     command: npx
#     args:
#       - -y
#       - "mcp-obsidian"
#       - /path/to/obsidian/vault

# Definition of custom endpoints
endpoints:
  # assistants:
  #   disableBuilder: false # Disable Assistants Builder Interface by setting to `true`
  #   pollIntervalMs: 3000  # Polling interval for checking assistant updates
  #   timeoutMs: 180000  # Timeout for assistant operations
  #   # Should only be one or the other, either `supportedIds` or `excludedIds`
  #   supportedIds: ["asst_supportedAssistantId1", "asst_supportedAssistantId2"]
  #   # excludedIds: ["asst_excludedAssistantId"]
  #   # Only show assistants that the user created or that were created externally (e.g. in Assistants playground).
  #   # privateAssistants: false # Does not work with `supportedIds` or `excludedIds`
  #   # (optional) Models that support retrieval, will default to latest known OpenAI models that support the feature
  #   retrievalModels: ["gpt-4-turbo-preview"]
  #   # (optional) Assistant Capabilities available to all users. Omit the ones you wish to exclude. Defaults to list below.
  #   capabilities: ["code_interpreter", "retrieval", "actions", "tools", "image_vision"]
  agents:
  #   # (optional) Default recursion depth for agents, defaults to 25
  #   recursionLimit: 50
  #   # (optional) Max recursion depth for agents, defaults to 25
  #   maxRecursionLimit: 100
  #   # (optional) Disable the builder interface for agents
  #   disableBuilder: false
  #   # (optional) Maximum total citations to include in agent responses, defaults to 30
  #   maxCitations: 30
  #   # (optional) Maximum citations per file to include in agent responses, defaults to 7
  #   maxCitationsPerFile: 7
  #   # (optional) Minimum relevance score for sources to be included in responses, defaults to 0.45 (45% relevance threshold)
  #   # Set to 0.0 to show all sources (no filtering), or higher like 0.7 for stricter filtering
  #   minRelevanceScore: 0.45
  #   # (optional) Agent Capabilities available to all users. Omit the ones you wish to exclude. Defaults to list below.
    capabilities: ["execute_code", "file_search", "actions", "tools"]

  # Anthropic endpoint configuration with Vertex AI support
  # Use this to run Anthropic Claude models through Google Cloud Vertex AI
  # anthropic:
  #   # (optional) Stream rate limiting in milliseconds
  #   streamRate: 20
  #   # (optional) Title model for conversation titles
  #   titleModel: claude-3.5-haiku  # Use the visible model name (key from models config)
  #
  #   # Vertex AI Configuration - enables running Claude models via Google Cloud
  #   # This is similar to Azure OpenAI but for Anthropic models on Google Cloud
  #   # Vertex AI is automatically enabled when this config section is present
  #   vertex:
  #     # Vertex AI region (optional, defaults to 'us-east5')
  #     # Available regions: us-east5, us-central1, europe-west1, europe-west4, asia-southeast1
  #     region: "us-east5"
  #     # Path to Google service account key file (optional)
  #     # If not specified, uses GOOGLE_SERVICE_KEY_FILE env var or default path (api/data/auth.json)
  #     # The project_id is automatically extracted from the service key file
  #     # serviceKeyFile: "/path/to/service-account.json"
  #     # Google Cloud Project ID (optional) - auto-detected from service key file
  #     # Only specify if you need to override the project_id in your service key
  #     # projectId: "${VERTEX_PROJECT_ID}"
  #
  #     # ============================================================================
  #     # Model Configuration - Set Visible Model Names and Deployment Mappings
  #     # Similar to Azure OpenAI model naming pattern
  #     # ============================================================================
  #
  #     # Option 1: Simple array (legacy format - model name = deployment name)
  #     # Use this if you want the technical model IDs to show in the UI
  #     # models:
  #     #   - "claude-sonnet-4-20250514"
  #     #   - "claude-3-7-sonnet-20250219"
  #     #   - "claude-3-5-sonnet-v2@20241022"
  #     #   - "claude-3-5-haiku@20241022"
  #
  #     # Option 2: Object format with custom visible names (RECOMMENDED)
  #     # The key is the visible model name shown in the UI (can be any name you want)
  #     # The deploymentName is the actual Vertex AI model ID used for API calls
  #     # You can use friendly names (avoid spaces for cleaner YAML) or technical IDs as keys
  #     models:
  #       claude-opus-4.5:
  #         deploymentName: claude-opus-4-5@20251101
  #       claude-sonnet-4:
  #         deploymentName: claude-sonnet-4-20250514
  #       claude-3.7-sonnet:
  #         deploymentName: claude-3-7-sonnet-20250219
  #       claude-3.5-sonnet:
  #         deploymentName: claude-3-5-sonnet-v2@20241022
  #       claude-3.5-haiku:
  #         deploymentName: claude-3-5-haiku@20241022
  #
  #     # Option 3: Mixed format with default deploymentName
  #     # Set a default deploymentName and use boolean values for models
  #     # deploymentName: claude-sonnet-4-20250514
  #     # models:
  #     #   claude-sonnet-4: true  # Will use the default deploymentName
  #     #   claude-3.5-haiku:
  #     #     deploymentName: claude-3-5-haiku@20241022  # Override for this model

  custom:
    # Groq Example
    - name: 'groq'
      apiKey: '${GROQ_API_KEY}'
      baseURL: 'https://api.groq.com/openai/v1/'
      models:
        default:
          - 'llama3-70b-8192'
          - 'llama3-8b-8192'
          - 'llama2-70b-4096'
          - 'mixtral-8x7b-32768'
          - 'gemma-7b-it'
        fetch: false
      titleConvo: true
      titleModel: 'mixtral-8x7b-32768'
      modelDisplayLabel: 'groq'

    # Mistral AI Example
    - name: 'Mistral' # Unique name for the endpoint
      # For `apiKey` and `baseURL`, you can use environment variables that you define.
      # recommended environment variables:
      apiKey: '${MISTRAL_API_KEY}'
      baseURL: 'https://api.mistral.ai/v1'

      # Models configuration
      models:
        # List of default models to use. At least one value is required.
        default: ['mistral-tiny', 'mistral-small', 'mistral-medium']
        # Fetch option: Set to true to fetch models from API.
        fetch: true # Defaults to false.

      # Optional configurations

      # Title Conversation setting
      titleConvo: true # Set to true to enable title conversation

      # Title Method: Choose between "completion" or "functions".
      # titleMethod: "completion"  # Defaults to "completion" if omitted.

      # Title Model: Specify the model to use for titles.
      titleModel: 'mistral-tiny' # Defaults to "gpt-3.5-turbo" if omitted.

      # Summarize setting: Set to true to enable summarization.
      # summarize: false

      # Summary Model: Specify the model to use if summarization is enabled.
      # summaryModel: "mistral-tiny"  # Defaults to "gpt-3.5-turbo" if omitted.

      # Force Prompt setting: If true, sends a `prompt` parameter instead of `messages`.
      # forcePrompt: false

      # The label displayed for the AI model in messages.
      modelDisplayLabel: 'Mistral' # Default is "AI" when not set.

      # Add additional parameters to the request. Default params will be overwritten.
      # addParams:
      # safe_prompt: true # This field is specific to Mistral AI: https://docs.mistral.ai/api/

      # Drop Default params parameters from the request. See default params in guide linked below.
      # NOTE: For Mistral, it is necessary to drop the following parameters or you will encounter a 422 Error:
      dropParams: ['stop', 'user', 'frequency_penalty', 'presence_penalty']

    # OpenRouter Example
    - name: 'OpenRouter'
      # For `apiKey` and `baseURL`, you can use environment variables that you define.
      # recommended environment variables:
      apiKey: 'user_provided'
      baseURL: 'https://openrouter.ai/api/v1'
      models:
        # Модели, которые будут предложены пользователю по умолчанию
        default:
          - 'google/gemini-2.5-flash-lite'
          - 'google/gemini-2.5-flash-lite:search'
          - 'google/gemini-2.5-flash'
          - 'google/gemini-2.5-pro'
          - 'google/gemini-2.0-flash-001'
          - 'google/gemma-3-27b-it'
          - 'openai/gpt-5'
          - 'openai/gpt-5-mini'
          - 'openai/gpt-5-nano'
          - 'openai/gpt-5-codex'
          - 'qwen/qwen3-coder:floor'
          - 'qwen/qwen3-coder-flash:floor' # Исправлена опечатка
          - 'qwen/qwen-plus-2025-07-28:floor'
          - 'qwen/qwen-plus-2025-07-28:thinking:floor'
          - 'anthropic/claude-sonnet-4.5:floor'
        fetch: true
      titleConvo: true
      titleModel: 'google/gemini-2.5-flash-lite'
      # Recommended: Drop the stop parameter from the request as Openrouter models use a variety of stop tokens.
      dropParams: ['stop']
      modelDisplayLabel: 'OpenRouter'

  # AWS Bedrock Example
  # Note: Bedrock endpoint is configured via environment variables
  # bedrock:
  #   # Guardrail Configuration
  #   guardrailConfig:
  #     guardrailIdentifier: "your-guardrail-id"
  #     guardrailVersion: "1"
  #
  #     # Trace behavior for debugging (optional)
  #     # - "enabled": Include basic trace information about guardrail assessments
  #     # - "enabled_full": Include comprehensive trace details (recommended for debugging)
  #     # - "disabled": No trace information (default)
  #     # Trace output is logged to application log files for compliance auditing
  #     trace: "enabled"

# Example modelSpecs configuration showing grouping options
# The 'group' field organizes model specs in the UI selector:
# - If 'group' matches an endpoint name (e.g., "openAI", "groq"), the spec appears nested under that endpoint
# - If 'group' is a custom name (doesn't match any endpoint), it creates a separate collapsible section
# - If 'group' is omitted, the spec appears as a standalone item at the top level
#
# The 'groupIcon' field sets an icon for custom groups:
# - Only needs to be set on one spec per group (first one is used)
# - Can be a URL or a built-in endpoint key (e.g., "openAI", "anthropic", "groq")
# modelSpecs:
#   list:
#     # Example 1: Nested under an endpoint (grouped with openAI endpoint)
#     - name: "gpt-4o"
#       label: "GPT-4 Optimized"
#       description: "Most capable GPT-4 model with multimodal support"
#       group: "openAI"  # String value matching the endpoint name
#       preset:
#         endpoint: "openAI"
#         model: "gpt-4o"
#
#     # Example 2: Nested under a custom endpoint (grouped with groq endpoint)
#     - name: "llama3-70b-8192"
#       label: "Llama 3 70B"
#       description: "Fastest inference available - great for quick responses"
#       group: "groq"  # String value matching your custom endpoint name from endpoints.custom
#       preset:
#         endpoint: "groq"
#         model: "llama3-70b-8192"
#
#     # Example 3: Custom group with icon (creates a separate collapsible section)
#     - name: "coding-assistant"
#       label: "Coding Assistant"
#       description: "Specialized for coding tasks"
#       group: "my-assistants"  # Custom string - doesn't match any endpoint, so creates its own group
#       groupIcon: "https://example.com/icons/assistants.png"  # Icon URL for the group
#       preset:
#         endpoint: "openAI"
#         model: "gpt-4o"
#         instructions: "You are an expert coding assistant..."
#         temperature: 0.3
#
#     - name: "writing-assistant"
#       label: "Writing Assistant"
#       description: "Specialized for creative writing"
#       group: "my-assistants"  # Same custom group name - both specs appear in same section
#       # No need to set groupIcon again - the first spec's icon is used
#       preset:
#         endpoint: "anthropic"
#         model: "claude-sonnet-4"
#         instructions: "You are a creative writing expert..."
#
#     # Example 4: Custom group using built-in icon key
#     - name: "fast-models"
#       label: "Fast Response Model"
#       group: "Fast Models"
#       groupIcon: "groq"  # Uses the built-in Groq icon
#       preset:
#         endpoint: "groq"
#         model: "llama3-8b-8192"
#
#     # Example 5: Standalone (no group - appears at top level)
#     - name: "general-assistant"
#       label: "General Assistant"
#       description: "General purpose assistant"
#       # No 'group' field - appears as standalone item at top level (not nested)
#       preset:
#         endpoint: "openAI"
#         model: "gpt-4o-mini"

# fileConfig:
#   endpoints:
#     assistants:
#       fileLimit: 5
#       fileSizeLimit: 10  # Maximum size for an individual file in MB
#       totalSizeLimit: 50  # Maximum total size for all files in a single request in MB
#       supportedMimeTypes:
#         - "image/.*"
#         - "application/pdf"
#     openAI:
#       disabled: true  # Disables file uploading to the OpenAI endpoint
#     default:
#       totalSizeLimit: 20
#     YourCustomEndpointName:
#       fileLimit: 2
#       fileSizeLimit: 5
#   serverFileSizeLimit: 100  # Global server file size limit in MB
#   avatarSizeLimit: 2  # Limit for user avatar image size in MB
#   imageGeneration: # Image Gen settings, either percentage or px
#     percentage: 100
#     px: 1024
#   # Client-side image resizing to prevent upload errors
#   clientImageResize:
#     enabled: false  # Enable/disable client-side image resizing (default: false)
#     maxWidth: 1900  # Maximum width for resized images (default: 1900)
#     maxHeight: 1900  # Maximum height for resized images (default: 1900)
#     quality: 0.92  # JPEG quality for compression (0.0-1.0, default: 0.92)
# # See the Custom Configuration Guide for more information on Assistants Config:
# # https://www.librechat.ai/docs/configuration/librechat_yaml/object_structure/assistants_endpoint

# Web Search Configuration (optional)
# webSearch:
#   # Jina Reranking Configuration
#   jinaApiKey: '${JINA_API_KEY}'  # Your Jina API key
#   jinaApiUrl: '${JINA_API_URL}'  # Custom Jina API URL (optional, defaults to https://api.jina.ai/v1/rerank)
#   # Other rerankers
#   cohereApiKey: '${COHERE_API_KEY}'
#   # Search providers
#   serperApiKey: '${SERPER_API_KEY}'
#   searxngInstanceUrl: '${SEARXNG_INSTANCE_URL}'
#   searxngApiKey: '${SEARXNG_API_KEY}'
#   # Content scrapers
#   firecrawlApiKey: '${FIRECRAWL_API_KEY}'
#   firecrawlApiUrl: '${FIRECRAWL_API_URL}'

# Memory configuration for user memories
# memory:
#   # (optional) Disable memory functionality
#   disabled: false
#   # (optional) Restrict memory keys to specific values to limit memory storage and improve consistency
#   validKeys: ["preferences", "work_info", "personal_info", "skills", "interests", "context"]
#   # (optional) Maximum token limit for memory storage (not yet implemented for token counting)
#   tokenLimit: 10000
#   # (optional) Enable personalization features (defaults to true if memory is configured)
#   # When false, users will not see the Personalization tab in settings
#   personalize: true
#   # Memory agent configuration - either use an existing agent by ID or define inline
#   agent:
#     # Option 1: Use existing agent by ID
#     id: "your-memory-agent-id"
#     # Option 2: Define agent inline
#     # provider: "openai"
#     # model: "gpt-4o-mini"
#     # instructions: "You are a memory management assistant. Store and manage user information accurately."
#     # model_parameters:
#     #   temperature: 0.1
