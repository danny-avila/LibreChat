# NGINX: Frontend web server and reverse proxy
---
# ConfigMap for nginx.conf
apiVersion: v1
kind: ConfigMap
metadata:
  name: nginx-config
  namespace: librechat
data:
  nginx.conf: |
    server {
        listen 80 default_server;
        listen [::]:80 default_server;
        server_name localhost;
     
        # Increase the client_max_body_size to allow larger file uploads
        # The default limits for image uploads as of 11/22/23 is 20MB/file, and 25MB/request
        client_max_body_size 25M;
        root /usr/share/nginx/html;
        
        location = /home { 
            try_files /index.html =404; 
        }
        # Proxy API requests
        location /api/ {
            proxy_pass http://librechat-api:3080$request_uri;
        }

        # Proxy everything else to LibreChat
        location / {
            proxy_pass http://librechat-api:3080/;
        }
    }

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx
  namespace: librechat
spec:
  replicas: 2  # Multiple replicas for load balancing
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.27.0-alpine
        ports:
        - containerPort: 80
        volumeMounts:
        - name: nginx-config
          mountPath: /etc/nginx/conf.d/default.conf
          subPath: nginx.conf
        resources:
          requests:
            memory: "128Mi"
            cpu: "50m"  # Reduced for single node
          limits:
            memory: "256Mi"
            cpu: "200m"
      volumes:
      - name: nginx-config
        configMap:
          name: nginx-config

---
# Service: Exposes NGINX to external traffic
apiVersion: v1
kind: Service
metadata:
  name: nginx
  namespace: librechat
spec:
  selector:
    app: nginx
  ports:
  - port: 80
    targetPort: 80
  type: LoadBalancer  # Creates external load balancer (cloud provider)
  # For on-premise, use NodePort or Ingress instead
