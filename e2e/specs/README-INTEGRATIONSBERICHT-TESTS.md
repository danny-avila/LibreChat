# Integrationsbericht BW 2025 - E2E Test Suite

## üéØ Zweck

Diese E2E-Tests stellen sicher, dass die **Sales-Demo-Reise** f√ºr den Integrationsbericht Baden-W√ºrttemberg 2025 **jederzeit funktioniert**.

**Ziel:** Engineering validiert automatisch, dass die Demo nicht kaputt geht, bevor Sales sie beim Kunden vorf√ºhrt.

---

## üìã Test-Dateien

### 1. **Complete Journey Test** (Haupt-Test)
**Datei:** `integrationsbericht-complete-journey.spec.ts`

**Was wird getestet:**
- ‚úÖ Komplette 6-Schritt Demo-Reise aus [INTEGRATIONSBERICHT-2025-DEMO.md](../../docs/senticor/INTEGRATIONSBERICHT-2025-DEMO.md)
- ‚úÖ Step 1: Projekt starten & Honeycomb erstellen
- ‚úÖ Step 2: Pressemitteilung einlesen
- ‚úÖ Step 3: Rechtliche Grundlagen recherchieren
- ‚úÖ Step 3b: Paragraphen zum Wissensgraph hinzuf√ºgen
- ‚úÖ Step 4: Projekt-Tracking-Struktur
- ‚úÖ Step 5: Berichtsgliederung generieren
- ‚úÖ Step 6: Suche & Analyse (Ehrenamt-Projekte, Gesamtstruktur)

**Dauer:** ~20 Minuten (mit echten AI-Antworten)

### 2. **Simple Tests** (Komponenten-Tests)
**Datei:** `integrationsbericht-demo-simple.spec.ts`

**Was wird getestet:**
- ‚úÖ UI-Verf√ºgbarkeit (Agents endpoint)
- ‚úÖ Honeycomb MCP Server erreichbar
- ‚úÖ Fetch MCP Server funktioniert
- ‚úÖ Rechtsinformationen MCP Server funktioniert
- ‚úÖ Proaktive KI-Vorschl√§ge

**Dauer:** ~5-10 Minuten pro Test

---

## üöÄ Tests ausf√ºhren

### Voraussetzungen

1. **LibreChat l√§uft:**
   ```bash
   podman-compose up -d
   ```

2. **HIVE API erreichbar:**
   ```bash
   curl http://localhost:8000/api/honeycombs
   # Sollte JSON mit honeycombs zur√ºckgeben
   ```

3. **Playwright installiert:**
   ```bash
   npx playwright install chromium
   ```

### Complete Journey Test (Empfohlen vor Sales-Demo)

```bash
# Mit sichtbarem Browser (f√ºr Debugging)
npx playwright test e2e/specs/integrationsbericht-complete-journey.spec.ts --headed --workers=1

# Headless (f√ºr CI/CD)
npx playwright test e2e/specs/integrationsbericht-complete-journey.spec.ts --workers=1

# Mit detailliertem Output
npx playwright test e2e/specs/integrationsbericht-complete-journey.spec.ts --headed --workers=1 --reporter=line
```

### Einzelne Komponenten testen

```bash
# Nur Smoke Test (MCP Servers)
npx playwright test e2e/specs/integrationsbericht-complete-journey.spec.ts --headed --grep "Smoke Test"

# Alle einfachen Tests
npx playwright test e2e/specs/integrationsbericht-demo-simple.spec.ts --headed --workers=1
```

---

## üìä Test-Output verstehen

### Erfolgreicher Test

```
üé¨ Starting Complete Integrationsbericht BW 2025 Demo Journey

üìã Step 0: Selecting Agents endpoint...
‚úÖ Agents endpoint selected

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
üìù STEP 1: Projekt starten & Wissensgraph erstellen
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

üì§ Sent: Ich erstelle den Integrationsbericht Baden-W√ºrttemberg 2025...
‚è≥ Waiting for AI response...
‚úÖ Response received containing: honeycomb
‚úÖ Step 1 Complete: AI suggested honeycomb creation

... (weitere Schritte)

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
üéâ DEMO JOURNEY COMPLETE!
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

‚úÖ All 6 steps executed successfully
üìä Sales team can now confidently perform this demo
üîó Honeycomb URL: http://localhost:8000/honeycomb/...
üì∏ Screenshot saved: /tmp/integrationsbericht-demo-complete.png
```

### Fehlgeschlagener Test

Wenn ein Schritt fehlschl√§gt, zeigt der Test genau wo:

```
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
üåê STEP 2: Pressemitteilung einlesen & Projekte erfassen
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

üì§ Sent: Ja, bitte lies die Pressemitteilung...
‚è≥ Waiting for AI response...
‚ùå Error: Timeout waiting for response
```

**Action:** Pr√ºfen ob fetch MCP Server l√§uft und URL erreichbar ist.

---

## ‚öôÔ∏è Konfiguration

### Test-Benutzer

Der Test erstellt automatisch einen dedizierten Demo-Benutzer:

```typescript
const DEMO_USER = {
  email: 'sales-demo@senticor.de',
  name: 'Senticor Sales Demo',
  password: 'SalesDemo2025!Secure',
};
```

Dieser Benutzer wird **automatisch registriert** beim ersten Testlauf.

### Timeouts

```typescript
FULL_JOURNEY_TIMEOUT = 1200000; // 20 Minuten f√ºr komplette Reise
PER_RESPONSE_TIMEOUT = 180000;  // 3 Minuten pro AI-Antwort
```

**Warum so lang?**
- Echte AI-Modelle (Gemini 2.5 Pro) brauchen 30-120s pro Antwort
- MCP-Aufrufe addieren 5-15s pro Tool-Call
- Komplexe Workflows (fetch + add_entity) k√∂nnen > 2 Min dauern

### Browser-Einstellungen

```typescript
headless: false,  // Browser sichtbar (zum Debugging)
slowMo: 300,      // 300ms Verz√∂gerung zwischen Aktionen
viewport: { width: 1920, height: 1080 }  // Full HD
```

---

## üîç Troubleshooting

### Test failed: "Cannot find Agents endpoint"

**Ursache:** LibreChat l√§uft nicht oder Agents endpoint nicht konfiguriert

**L√∂sung:**
```bash
# Pr√ºfen ob LibreChat l√§uft
podman ps | grep LibreChat

# Neu starten
podman-compose down && podman-compose up -d

# librechat.yaml pr√ºfen
cat librechat.yaml | grep -A5 "endpoints:"
```

### Test failed: "MCP server not responding"

**Ursache:** Einer der MCP-Server (honeycomb, fetch, rechtsinformationen) ist nicht erreichbar

**L√∂sung:**
```bash
# HIVE API pr√ºfen
curl http://localhost:8000/api/honeycombs

# Container logs pr√ºfen
podman logs LibreChat | grep MCP

# MCP-Konfiguration pr√ºfen
cat librechat.yaml | grep -A10 "mcpServers:"
```

### Test timeout: "Waiting for AI response"

**Ursache:** AI-Modell braucht l√§nger als erwartet (normal!)

**L√∂sung:**
1. **Kurzfristig:** Test erneut ausf√ºhren (manchmal ist Gemini einfach langsam)
2. **Mittelfristig:** Timeout erh√∂hen auf 240s
3. **Langfristig:** Schnelleres Modell f√ºr Tests (Gemini Flash statt Pro)

### Screenshot nicht erstellt

**Ursache:** Test ist vor Ende abgebrochen

**L√∂sung:**
```bash
# Manuell Screenshot erzeugen
npx playwright test --headed --debug
# Im Debug-Modus: Pause before screenshot
```

---

## ü§ñ CI/CD Integration

### GitHub Actions Workflow

```yaml
name: Integrationsbericht Demo E2E

on:
  schedule:
    - cron: '0 8 * * 1'  # Jeden Montag um 8:00
  push:
    branches:
      - main
    paths:
      - 'librechat.yaml'
      - 'docs/senticor/INTEGRATIONSBERICHT-2025-DEMO.md'

jobs:
  demo-test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Start LibreChat
        run: docker-compose up -d

      - name: Install Playwright
        run: npx playwright install chromium

      - name: Run Complete Journey Test
        run: npx playwright test e2e/specs/integrationsbericht-complete-journey.spec.ts --workers=1
        timeout-minutes: 25

      - name: Upload Screenshot
        if: failure()
        uses: actions/upload-artifact@v3
        with:
          name: demo-screenshot
          path: /tmp/integrationsbericht-demo-complete.png

      - name: Notify Sales Team
        if: failure()
        run: |
          curl -X POST ${{ secrets.SLACK_WEBHOOK }} \
            -d '{"text":"‚ö†Ô∏è Integrationsbericht Demo ist kaputt! Sales-Demo NICHT durchf√ºhren bis Engineering gefixed hat."}'
```

### Wann Tests laufen sollten

1. **Vor jedem Sales-Call:** Manuell ausf√ºhren
   ```bash
   npx playwright test e2e/specs/integrationsbericht-complete-journey.spec.ts --headed --workers=1
   ```

2. **Nach Config-√Ñnderungen:** Automatisch in CI/CD
   - √Ñnderungen an `librechat.yaml`
   - √Ñnderungen an MCP-Server-Konfiguration
   - √Ñnderungen an Demo-Dokumentation

3. **W√∂chentlich:** Scheduled CI/CD Run
   - Jeden Montag morgen
   - Stellt sicher, dass externe APIs noch funktionieren (gesetze-im-internet.de)

---

## üìà Test-Metriken

### Was wird gemessen

1. **Test-Dauer:** Sollte < 25 Minuten sein
2. **AI-Antwortzeit:** Pro Schritt 30-180 Sekunden
3. **MCP-Verf√ºgbarkeit:** 100% (alle 3 Server erreichbar)
4. **Erfolgsrate:** > 95% (gelegentliche Timeouts sind normal)

### Aktuelle Baseline (2025-10-10)

```
Complete Journey Test:
  ‚îú‚îÄ Step 1 (Honeycomb):        45s
  ‚îú‚îÄ Step 2 (Fetch):             120s
  ‚îú‚îÄ Step 3 (Legal Research):    90s
  ‚îú‚îÄ Step 3b (Add Laws):         150s
  ‚îú‚îÄ Step 4 (Tracking):          60s
  ‚îú‚îÄ Step 5 (Outline):           80s
  ‚îî‚îÄ Step 6 (Search):            75s

Total: ~12 Minuten
```

---

## üìö Verwandte Dokumentation

### F√ºr Engineering
- [DEMO-TEST-REPORT.md](../../docs/senticor/DEMO-TEST-REPORT.md) - Test-Ergebnisse
- [LIBRECHAT-MCP-BUG-REPORT.md](../../docs/senticor/LIBRECHAT-MCP-BUG-REPORT.md) - Bekannte Bugs
- [PROACTIVE-AGENT-SETUP.md](../../docs/senticor/PROACTIVE-AGENT-SETUP.md) - MCP-Konfiguration

### F√ºr Sales
- [INTEGRATIONSBERICHT-2025-DEMO.md](../../docs/senticor/INTEGRATIONSBERICHT-2025-DEMO.md) - Demo-Skript
- [populate-integrationsbericht.sh](../../docs/senticor/populate-integrationsbericht.sh) - Demo-Daten erstellen

---

## üéØ Erfolgs-Kriterien

Ein Test gilt als **erfolgreich**, wenn:

‚úÖ Alle 6 Schritte durchlaufen wurden
‚úÖ AI hat proaktiv Honeycomb vorgeschlagen (Step 1)
‚úÖ Pressemitteilung wurde gelesen (Step 2)
‚úÖ Deutsche Gesetze wurden gefunden (Step 3)
‚úÖ Berichtsgliederung wurde generiert (Step 5)
‚úÖ Suche nach Ehrenamt-Projekten liefert Ergebnisse (Step 6)
‚úÖ Screenshot wurde erstellt
‚úÖ Keine kritischen Fehler in Console

Ein Test ist **fehlgeschlagen**, wenn:

‚ùå MCP-Server nicht erreichbar
‚ùå AI antwortet nicht (Timeout > 3 Min)
‚ùå LibreChat UI l√§dt nicht
‚ùå Agents endpoint nicht verf√ºgbar
‚ùå Demo-Benutzer kann nicht erstellt werden

---

## üí° Best Practices

### Vor Sales-Demo (Engineering Checklist)

```bash
# 1. Test ausf√ºhren
npx playwright test e2e/specs/integrationsbericht-complete-journey.spec.ts --headed --workers=1

# 2. Bei Erfolg: Demo-Daten populieren
bash docs/senticor/populate-integrationsbericht.sh

# 3. HIVE UI √∂ffnen und visuell pr√ºfen
open http://localhost:8000/honeycomb/hc_bericht_integration_baden_wuerttemberg_2025

# 4. Sales-Team informieren
echo "‚úÖ Demo ist ready - all systems go!"
```

### Nach fehlgeschlagenem Test

1. **NICHT Sales-Demo durchf√ºhren** bis der Test gr√ºn ist!
2. Logs pr√ºfen: `/tmp/complete-journey-test.log`
3. MCP-Server-Status pr√ºfen: `podman logs LibreChat | grep MCP`
4. Bei Bedarf LibreChat neu starten
5. Test erneut ausf√ºhren
6. Bei weiterem Fehler: Engineering-Team eskalieren

---

**Maintainer:** Engineering Team
**Letzte Aktualisierung:** 2025-10-10
**Test-Version:** 1.0.0
