apiVersion: v1
kind: ConfigMap
metadata:
  name: librechat-yaml
  namespace: librechat
data:
  librechat.yaml: |
    # For more information, see the Configuration Guide:
    # https://www.librechat.ai/docs/configuration/librechat_yaml
     
    # Configuration version (required)
    version: 1.2.8
    cache: false


    interface:
      agents: false
      multiConvo: false


    memory:
      disabled: false  # Set to true to completely disable memory
      personalize: true  # Gives users the ability to toggle memory on/off, true by default
      tokenLimit: 2000  # Maximum tokens for memory storage
      messageWindowSize: 5  # Number of recent messages to consider
      agent:
        provider: "OpenAI_models"
        model: "gpt-4o-mini"
        instructions: |
          Store information only in the specified validKeys categories.
          Focus on explicitly stated preferences and important facts.
          Delete outdated or corrected information promptly.

    endpoints:
      agents:
        disableBuilder: true
        # (optional) Agent Capabilities available to all users. Omit the ones you wish to exclude. Defaults to list below.
        capabilities: ["file_search","context"]
        # (optional) File citation configuration for file_search capability

      custom:
        - name: "OpenAI_models"
          apiKey: "sk-P6M79NDniLcy6-sfdkcOcA"   # or ${MASTER_KEY}
          baseURL: "http://litellm:8000/v1"
          models:
            default: ["gpt-4o-mini"]
            fetch: true
          titleConvo: true
          titleModel: "current_model"
          modelDisplayLabel: "OpenAi"
          
        - name: "Anthropic_models"
          apiKey: "sk-uhyZxnKRSglt3WOhYKSjFg"   # or ${MASTER_KEY}
          baseURL: "http://litellm:8000/v1"
          models:
            default: ["claude-haiku-4-5"]
            fetch: true
          titleConvo: true
          titleModel: "current_model"
          modelDisplayLabel: "Anthropic"

        # - name: "Meta_models"
        #   apiKey: "sk-FYDXelAfyVefuK8m6gMQ3A"   # or ${MASTER_KEY}
        #   baseURL: "http://litellm:8000/v1"
        #   models:
        #     default: ["ollama/llama3.1"]
        #     fetch: true
        #   titleConvo: true
        #   titleModel: "current_model"
        #   modelDisplayLabel: "Meta"

        # - name: "Google_models"
        #   apiKey: "sk-k9T8EotqQTOG_DcEhrtr9g"   # or ${MASTER_KEY}
        #   baseURL: "http://litellm:8000/v1"
        #   models:
        #     default: ["ollama/gemma3"]
        #     fetch: true
        #   titleConvo: true
        #   titleModel: "current_model"
        #   modelDisplayLabel: "Google"
