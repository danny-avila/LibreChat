services:

  models_watcher:
    image: alpine:3.20
    depends_on:
      - litellm
      - api
    #restart: always
    environment:
      LITELLM_MASTER_KEY: ${LITELLM_MASTER_KEY}
      LITELLM_MODELS_URL: "http://litellm:8000/v1/models"
      CHECK_EVERY: "10"
      TARGET_CONTAINER: "LibreChat-API"
    volumes:
      - ./watch_models.sh:/watch_models.sh:ro
      - /var/run/docker.sock:/var/run/docker.sock
    command: [ "sh", "-lc", "apk add --no-cache curl docker-cli openssl >/dev/null && /watch_models.sh" ]

  # ollama:
  #   image: ollama/ollama:latest
  #   container_name: ollama
  #   restart: always
  #   ports:
  #     - "11434:11434"
  #   volumes:
  #     - ollama_models:/root/.ollama
  #   environment:
  #     - OLLAMA_KEEP_ALIVE=24h
  #   gpus: all




  wait_for_litellm:
    image: curlimages/curl:8.9.1
    #restart: "no"
    depends_on:
      - litellm
    command:
      - sh
      - -lc
      - |
        echo "Waiting for LiteLLM at http://litellm:8000/v1/models ..."
        until curl -sf -H "Authorization: Bearer ${LITELLM_MASTER_KEY}" http://litellm:8000/v1/models >/dev/null; do
          sleep 2
        done
        echo "LiteLLM is ready."

  api:
    build:
      context: .
      dockerfile: Dockerfile
    image: librechat-custom-logo:latest
    # image: ghcr.io/danny-avila/librechat-dev-api:latest
    container_name: LibreChat-API
    ports:
      - 3080:3080
    depends_on:
      mongodb:
        condition: service_started
      rag_api:
        condition: service_started
      litellm:
        condition: service_started
      wait_for_litellm:
        condition: service_completed_successfully 
    #restart: always
    extra_hosts:
    - "host.docker.internal:host-gateway"
    env_file:
      - .env
    environment:
      - NODE_ENV=development
      - MONGO_URI=mongodb://${LIBRECHAT_DB_USER}:${LIBRECHAT_DB_PASS_URL}@mongodb:27017/LibreChat?authSource=LibreChat
      - MEILI_HOST=http://meilisearch:7700
    volumes:
      - type: bind
        source: ./librechat.yaml
        target: /app/librechat.yaml
      - ./images:/app/client/public/images
      - ./uploads:/app/uploads
      - ./logs:/app/api/logs

  client:
    image: nginx:1.27.0-alpine
    container_name: LibreChat-NGINX
    ports:
      - 80:80
      - 443:443
    depends_on:
      - api
      - litellm
    #restart: always
    volumes:
      - ./client/nginx.conf:/etc/nginx/conf.d/default.conf
      - ./front-page/index.html:/usr/share/nginx/html/index.html:ro

  mongodb:
    container_name: chat-mongodb
    ports:  # Uncomment this to access mongodb from outside docker, not safe in deployment
      - 27018:27017
    image: mongo
    #restart: always
    environment:
      MONGO_INITDB_ROOT_USERNAME: ${MONGO_ROOT_USER}
      MONGO_INITDB_ROOT_PASSWORD: ${MONGO_ROOT_PASS}
      LIBRECHAT_DB_USER: ${LIBRECHAT_DB_USER}
      LIBRECHAT_DB_PASS_URL: ${LIBRECHAT_DB_PASS_URL}
    volumes:
      - ./data-node:/data/db
      - ./mongo-init.js:/docker-entrypoint-initdb.d/mongo-init.js:ro
    command: mongod --auth --bind_ip_all

  meilisearch:
    container_name: chat-meilisearch
    image: getmeili/meilisearch:v1.12.3
    #restart: always
    # ports: # Uncomment this to access meilisearch from outside docker
    #   - 7700:7700 # if exposing these ports, make sure your master key is not the default value
    env_file:
      - .env
    environment:
      - MEILI_HOST=http://meilisearch:7700
      - MEILI_NO_ANALYTICS=true
    volumes:
      - ./meili_data_v1.12:/meili_data

  vectordb:
    image: pgvector/pgvector:0.8.0-pg15-trixie
    env_file:
      - .env
    #restart: always
    volumes:
      - pgdata2:/var/lib/postgresql/data

  rag_api:
    image: ghcr.io/danny-avila/librechat-rag-api-dev-lite:latest
    #restart: always
    depends_on:
      - vectordb
    environment:
      - DB_HOST=vectordb
      - RAG_PORT=${RAG_PORT:-8000}
    env_file:
      - .env

  litellm:
    image: ghcr.io/berriai/litellm:main-latest
    environment:
      LITELLM_MASTER_KEY: ${LITELLM_MASTER_KEY}
      DATABASE_URL: ${DATABASE_URL}
      LITELLM_SALT_KEY: ${LITELLM_SALT_KEY}
      STORE_MODEL_IN_DB: ${STORE_MODEL_IN_DB}
      

    volumes:
      - ./litellm/litellm-config.yaml:/app/config.yaml
#      - ./litellm/application_default_credentials.json:/app/application_default_credentials.json # only if using Google Vertex
    ports:
      - "4000:8000"
    depends_on:
      - vectordb
      #- ollama
    #restart: always
    command: [ "--config", "/app/config.yaml", "--port", "8000", "--num_workers", "8" ]  

volumes:
  pgdata2:
  #ollama_models:
